# Глоссарий

Эта глава служит опорной точкой. Сюда можно возвращаться, если термин встречается в коде, формуле или описании алгоритма и хочется быстро освежить смысл без погружения в теорию.

#### Алгоритм

Алгоритм – это конечная последовательность шагов, которая преобразует входные данные в результат. В машинном обучении алгоритм обычно определяет, как именно мы подбираем параметры модели: например, градиентный спуск, стохастический градиентный спуск или \
$$k$$-ближайших соседей.

Важно различать модель и алгоритм: модель – это форма зависимости, алгоритм – способ ее обучения или применения.

#### Аффинное преобразование

Аффинное преобразование – это преобразование вида

$$
y = Wx + b
$$

где $$W$$ – матрица весов, $$x$$  – входной вектор признаков, а $$b$$ – вектор смещений (bias).

Геометрически аффинное преобразование сочетает в себе линейное преобразование (повороты, растяжения, сжатия, отражения) и сдвиг. В отличие от чисто линейного преобразования, оно не обязано сохранять начало координат.

В машинном обучении аффинное преобразование лежит в основе большинства моделей:

* линейной и логистической регрессии
* полносвязных слоев нейросетей
* преобразования эмбеддингов и признаков

Практически любая модель сначала выполняет аффинное преобразование входных данных, а затем применяет нелинейность или функцию решения. Поэтому выражение $$Wx + b$$ \$$ можно считать фундаментальным строительным блоком современного ML.

Интуитивно аффинное преобразование отвечает за то, как модель "перевзвешивает" признаки и сдвигает результат в нужную область пространства.

#### Attention-механизм

Attention-механизм – это способ позволить модели избирательно "обращать внимание" на разные части входных данных в зависимости от контекста задачи.

Идея "внимания" состоит в том, что не все элементы входа одинаково важны. Для каждого элемента модель вычисляет, насколько сильно он связан с текущим запросом, и на основе этого взвешивает вклад информации.

В математической форме attention строится вокруг скалярных произведений. Для каждого элемента вычисляются три вектора:

* Query (Q) – что мы сейчас ищем
* Key (K) – что представляет каждый элемент
* Value (V) – какую информацию он несет

Оценка важности обычно вычисляется как скалярное произведение $$Q \cdot K$$, после чего применяется нормализация (чаще всего softmax). Итоговый результат – это взвешенная сумма векторов $$V$$.

Attention-механизмы лежат в основе трансформеров и современных языковых моделей. Они позволяют учитывать зависимости между словами независимо от расстояния в тексте, что принципиально отличает их от классических последовательных моделей.

Интуитивно attention можно представить как динамический механизм фокуса: модель каждый раз по-новому решает, какие части входа важны именно сейчас. С практической точки зрения attention – это обобщение идеи сходства векторов, доведенное до масштаба целых моделей.

#### Bag-of-Words (мешок слов)

Bag-of-Words (BoW) – это способ представить текст в виде числового вектора. Каждый элемент вектора соответствует слову из словаря, а значение показывает, сколько раз это слово встретилось в тексте.

При этом порядок слов полностью игнорируется. Фразы "PHP любит ML" и "ML любит PHP" будут иметь одинаковое представление.

BoW прост, быстр и хорошо подходит для первых экспериментов, но плохо передает смысл и контекст.

#### Bias (смещение)

Bias – это свободный член модели, позволяющий сдвигать результат независимо от входных признаков. В линейной регрессии bias соответствует члену $$b$$ в формуле

$$
y = wx + b
$$

Интуитивно bias отвечает за “базовый уровень” предсказания.

#### Cosine Similarity (косинусное сходство)

Cosine similarity – мера сходства двух векторов, основанная на косинусе угла между ними:

$$
cos(\theta) = \frac{A \cdot B}{|A||B|}
$$

Она показывает, насколько два вектора направлены в одну сторону, игнорируя их длину. Это особенно важно при работе с текстами, эмбеддингами и TF-IDF.

Cosine similarity часто предпочтительнее евклидова расстояния для текстов, потому что нас интересует не абсолютный масштаб, а смысловое направление.

#### Вектор

Вектор – упорядоченный набор чисел, представляющий объект. В машинном обучении почти все является вектором: строка текста, пользователь, событие, изображение.

Работа с векторами – фундамент ML.

#### Данные

Данные – это наблюдения, представленные в числовой форме. В контексте машинного обучения данные почти всегда интерпретируются как точки в многомерном пространстве, где каждая координата – это признак.

Тексты, изображения, события, пользователи – все в итоге сводится к векторам чисел.

#### Dot product (скалярное произведение)

Скалярное произведение – это операция над двумя векторами, результатом которой является одно число. В координатной форме оно определяется как сумма произведений соответствующих компонент:

$$
A \cdot B = \sum_i A_i B_i
$$

Геометрически скалярное произведение выражается через длины векторов и угол между ними:

$$
A \cdot B = |A| |B| \cos(\theta)
$$

Из этой формулы напрямую следует cosine similarity, которая по сути является нормированным скалярным произведением.

В машинном обучении скалярное произведение встречается повсюду. Линейная модель вычисляет предсказание как скалярное произведение вектора признаков и вектора весов с добавлением bias. Поиск похожих объектов, работа с эмбеддингами, TF-IDF и Bag-of-Words также сводятся к скалярным произведениям между векторами.

Интуитивно скалярное произведение отвечает на вопрос: "Насколько два вектора смотрят в одну сторону?" Если оно большое и положительное, объекты похожи; если близко к нулю – почти независимы; если отрицательное – направлены в разные стороны.

С практической точки зрения скалярное произведение – это базовая операция, вокруг которой построена большая часть классических и современных алгоритмов машинного обучения.

#### Embeddings (эмбеддинги)

Эмбеддинги – это плотные векторные представления объектов (слов, предложений, документов, изображений), которые кодируют их смысл.

В отличие от Bag-of-Words, эмбеддинги:

* имеют фиксированную размерность
* учитывают семантику
* позволяют сравнивать смысл, а не просто совпадение слов

Современные эмбеддинги обычно получаются с помощью нейросетей и активно используются в поиске, рекомендациях и RAG-системах.

#### Евклидово расстояние

Евклидово расстояние – обычное расстояние “по линейке” между двумя точками:

$$
d(A, B) = \sqrt{\sum (A_i - B_i)^2}
$$

Оно хорошо работает для числовых данных, но часто уступает cosine similarity для текстов и эмбеддингов.

#### Feature (признак)

Признак – это измеримая характеристика объекта. Для квартиры это может быть площадь, для пользователя – возраст, для текста – частота слова или значение эмбеддинга.

Модель работает не с "реальными объектами", а с их признаками.

#### Feature Engineering

Feature engineering – процесс преобразования сырых данных в признаки, удобные для модели. Это может быть нормализация чисел, кодирование категорий, построение TF-IDF или генерация дополнительных признаков.

На практике качество признаков часто важнее выбора конкретного алгоритма.

#### Градиент

Градиент – это вектор производных функции по всем ее параметрам. Он указывает направление наибольшего роста функции в многомерном пространстве.

Если функция зависит от параметров $$w_1, w_2, \dots, w_n$$, то градиент записывается как:

$$
\nabla f = \left( \frac{\partial f}{\partial w_1}, \frac{\partial f}{\partial w_2}, \dots, \frac{\partial f}{\partial w_n} \right)
$$

Геометрически градиент перпендикулярен линиям равного значения функции и показывает, куда "идет вверх" поверхность ошибки. Поэтому для минимизации функции (например, loss-функции) двигаются в противоположном направлении – против градиента.

В машинном обучении градиент используется для:

* обновления параметров модели
* обучения линейных моделей и нейросетей
* оптимизации MSE, log loss и других функций

Интуитивно градиент отвечает на вопрос: "В какую сторону нужно изменить параметры, чтобы ошибка росла быстрее всего?" А значит, двигаясь в обратную сторону, мы быстрее всего уменьшаем ошибку.

С практической точки зрения почти все обучение моделей сводится к вычислению градиентов и небольшим шагам в пространстве параметров.

#### Градиентный спуск

Градиентный спуск – алгоритм оптимизации, который подбирает параметры модели, двигаясь в сторону уменьшения ошибки.

Он основан на вычислении производной (градиента) функции ошибки по параметрам модели и является базовым инструментом для линейных моделей и нейросетей.

#### Лемматизация

Лемматизация – это приведение слов к их базовой, словарной форме (лемме).

Например:

"бежал", "бегу", "бегут" → "бежать"

"книги", "книгой", "книгах" → "книга"

В отличие от простого стемминга, лемматизация учитывает морфологию и часть речи, поэтому результат обычно более корректен с точки зрения языка.

В задачах машинного обучения лемматизация используется как этап предобработки текста перед Bag-of-Words, TF-IDF или обучением моделей. Она уменьшает размер словаря и помогает модели лучше обобщать смысл, а не формы слов.

#### L1-регуляризация

L1-регуляризация – это регуляризация, основанная на сумме абсолютных значений весов модели:

$$
\text{Loss} = \text{Loss}_{\text{data}} + \lambda \sum |w_i|
$$

Ее ключевая особенность в том, что она стремится обнулять некоторые коэффициенты полностью. В результате модель начинает использовать только часть признаков, а остальные фактически отбрасывает.

С практической точки зрения L1-регуляризация выполняет неявный отбор признаков и особенно полезна в задачах с большим количеством признаков, например при использовании Bag-of-Words или TF-IDF.

Из-за этой особенности оптимизация с L1-регуляризацией сложнее, чем с L2, но итоговая модель часто получается более интерпретируемой.

#### L2-регуляризация

L2-регуляризация – это способ борьбы с переобучением, при котором модель штрафуется за слишком большие значения параметров.

Идея проста: если коэффициенты модели становятся слишком большими, значит она начинает слишком точно подгоняться под обучающие данные. L2-регуляризация добавляет к функции ошибки дополнительный член, зависящий от квадратов весов:

$$
\text{Loss} = \text{Loss}_{\text{data}} + \lambda \sum w_i^2
$$

Здесь $$\lambda$$ – коэффициент регуляризации, определяющий силу штрафа.

Интуитивно L2-регуляризация "размазывает" влияние признаков, заставляя модель использовать их более равномерно. Коэффициенты обычно становятся маленькими, но редко обнуляются полностью.

L2-регуляризация особенно хорошо работает в линейных моделях и логистической регрессии, когда признаки коррелированы между собой.

#### Loss-функция

Loss-функция измеряет, насколько плохо модель предсказывает результат на конкретном примере. Примеры:

* MSE для регрессии
* log loss для классификации

Минимизация loss-функции – центральная задача обучения модели.

#### MLE (Maximum Likelihood Estimation)

MLE – метод максимального правдоподобия, способ оценки параметров модели, при котором выбираются такие параметры, при которых наблюдаемые данные наиболее вероятны.

Идея MLE состоит в том, что мы не минимизируем ошибку напрямую, а максимизируем вероятность получить именно те данные, которые мы видим, при заданной модели.

Формально это выглядит как максимизация функции правдоподобия:

$$
\mathcal{L}(\theta) = p(y \mid x, \theta)
$$

На практике чаще работают с логарифмом правдоподобия, так как он удобнее для вычислений.

Важный и полезный факт: для линейной регрессии с гауссовским шумом максимизация правдоподобия эквивалентна минимизации MSE. Именно поэтому MSE возникает не как произвольная формула, а как следствие вероятностных предположений о данных.

MLE лежит в основе многих моделей:

* линейной и логистической регрессии
* обобщенных линейных моделей
* нейросетей (через log loss и cross-entropy)

Интуитивно MLE отвечает на вопрос: "При каких параметрах модели наблюдаемые данные выглядели бы наименее удивительными?"

С практической точки зрения MLE связывает машинное обучение с вероятностью и статистикой и позволяет осмысленно выбирать loss-функции, а не подбирать их наугад.

#### MSE (Mean Squared Error)

MSE – среднеквадратичная ошибка, одна из самых распространенных loss-функций для задач регрессии.

Она измеряет средний квадрат разницы между предсказанием модели и истинным значением:

$$
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

Возведение ошибки в квадрат усиливает влияние больших отклонений, поэтому MSE особенно чувствительна к выбросам.

С интуитивной точки зрения MSE отвечает на вопрос: "Насколько в среднем модель промахивается, если крупные ошибки считать особенно плохими?"

MSE хорошо сочетается с линейными моделями, потому что:

* она гладкая и дифференцируемая
* имеет простой градиент
* приводит к удобным аналитическим и численным решениям

В градиентном спуске производная MSE по параметрам модели прямо указывает направление, в котором нужно уменьшать ошибку.

На практике MSE часто используется не только как метрика качества, но и как функция, которую модель минимизирует в процессе обучения.

#### Модель

Модель – это математическая функция с параметрами, которая аппроксимирует зависимость между входными данными и результатом.

Примеры:

* линейная регрессия
* логистическая регрессия
* нейросеть

Модель не "знает" мир – она лишь приближает его на основе данных.

#### Нормализация

Нормализация – приведение признаков к сопоставимому масштабу. Например, значения в диапазон \[0, 1] или с нулевым средним и единичной дисперсией.

Без нормализации многие алгоритмы обучаются хуже или нестабильно.

#### One-hot encoding

One-hot encoding – это способ кодирования категориальных признаков в числовой вид с помощью бинарных векторов.

Каждой категории соответствует отдельная координата вектора. Для конкретного объекта ровно одна координата равна 1, а все остальные равны 0.

Например, признак "цвет" со значениями {красный, зеленый, синий} может быть закодирован так:

красный → \[1, 0, 0]

зеленый → \[0, 1, 0]

синий → \[0, 0, 1]

One-hot encoding широко используется в линейных моделях, логистической регрессии и нейросетях, когда категории не имеют естественного порядка.

Главный недостаток one-hot encoding – рост размерности признакового пространства при большом количестве категорий. В текстовых задачах Bag-of-Words и TF-IDF по сути являются частным случаем one-hot представления, взвешенного по частоте.

В более сложных моделях и при большом числе категорий one-hot encoding часто заменяют эмбеддингами, которые позволяют компактно представить категориальные данные и учитывать скрытые связи между ними.

#### Ортогональные векторы

Ортогональные векторы – это векторы, которые перпендикулярны друг другу. Формально это означает, что их скалярное произведение равно нулю:

$$
A \cdot B = 0
$$

Геометрически ортогональность означает отсутствие проекции одного вектора на другой. Векторы не имеют общего направления и считаются полностью независимыми в смысле ориентации в пространстве.

В машинном обучении ортогональные векторы интерпретируются как несвязанные или несхожие признаки. Например, если cosine similarity равна нулю, соответствующие векторы ортогональны и не имеют смыслового пересечения.

Ортогональность играет важную роль в:

* линейной алгебре и базисах признаков
* снижении корреляции между признаками
* анализе эмбеддингов
* attention-механизмах, где ортогональные key-векторы не влияют на результат

Интуитивно ортогональные векторы отвечают ситуации, когда знание одного признака не дает информации о другом. Это понятие помогает понять, почему одни признаки усиливают друг друга, а другие не взаимодействуют вовсе.

#### Переобучение (Overfitting)

Переобучение возникает, когда модель слишком хорошо запоминает обучающие данные, но плохо обобщает на новые.

Обычно это следствие слишком сложной модели или недостатка данных.

#### Пространство признаков

Пространство признаков – это абстрактное пространство, в котором каждая ось соответствует одному признаку, а каждый объект – точка в этом пространстве.

Именно в этом пространстве мы считаем расстояния, углы и сходство.

#### Стемминг

Стемминг – это упрощенный способ приведения слов к общей основе (стему) путем механического отсечения окончаний и суффиксов.

Например:

"бегу”, "бежал", "бегущий" → "бег"

"connection", "connected", "connecting" → "connect"

В отличие от лемматизации, стемминг:

* не опирается на словари и грамматику
* работает быстрее
* может порождать формы, которые не являются реальными словами

Стемминг часто используется как быстрый этап предобработки текста перед Bag-of-Words или TF-IDF, особенно в задачах, где точная языковая форма менее важна, чем общая тема документа.

Недостаток стемминга в том, что он может объединять слова с разным смыслом или, наоборот, не объединять близкие по значению формы. Поэтому в более точных системах, особенно для сложных языков, чаще предпочитают лемматизацию.

В практическом смысле выбор между стеммингом и лемматизацией – это компромисс между скоростью, простотой и качеством смыслового представления текста.

#### Стоп-слова

Стоп-слова – это часто встречающиеся слова, которые обычно несут мало смысловой нагрузки: "и", "в", "на", "это", "the", "is" и т.д.

При анализе текста такие слова часто удаляют, чтобы:

* уменьшить размерность признаков
* снизить шум
* сосредоточиться на содержательных словах

Стоп-слова особенно актуальны при использовании Bag-of-Words и TF-IDF. Однако при работе с современными эмбеддингами и нейросетями их удаление не всегда необходимо и иногда даже вредно, поскольку модель может использовать контекст, в том числе служебные слова.

#### TF-IDF

TF-IDF (Term Frequency – Inverse Document Frequency) – улучшенная версия Bag-of-Words, которая учитывает не только частоту слова в документе, но и его редкость во всей коллекции.

Редкие, но информативные слова получают больший вес, чем частые служебные.

TF-IDF часто используется как базовое представление текста перед классификацией или поиском.

#### Train / Test split

Train/Test split – разделение данных на обучающую и тестовую выборки. Модель обучается на одной части данных и проверяется на другой.

Это позволяет оценить, насколько хорошо модель обобщает знания.
