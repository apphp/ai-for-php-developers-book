# Глоссарий

Эта глава служит опорной точкой. Сюда можно возвращаться, если термин встречается в коде, формуле или описании алгоритма и хочется быстро освежить смысл без погружения в теорию.

#### Алгоритм

Алгоритм – это конечная последовательность шагов, которая преобразует входные данные в результат. В машинном обучении алгоритм обычно определяет, как именно мы подбираем параметры модели: например, градиентный спуск, стохастический градиентный спуск или \
$$k$$-ближайших соседей.

Важно различать модель и алгоритм: модель – это форма зависимости, алгоритм – способ ее обучения или применения.

#### Аффинное преобразование

Аффинное преобразование – это преобразование вида

$$
y = Wx + b
$$

где $$W$$ – матрица весов, $$x$$  – входной вектор признаков, а $$b$$ – вектор смещений (bias).

Геометрически аффинное преобразование сочетает в себе линейное преобразование (повороты, растяжения, сжатия, отражения) и сдвиг. В отличие от чисто линейного преобразования, оно не обязано сохранять начало координат.

В машинном обучении аффинное преобразование лежит в основе большинства моделей:

* линейной и логистической регрессии
* полносвязных слоев нейросетей
* преобразования эмбеддингов и признаков

Практически любая модель сначала выполняет аффинное преобразование входных данных, а затем применяет нелинейность или функцию решения. Поэтому выражение $$Wx + b$$ \$$ можно считать фундаментальным строительным блоком современного ML.

Интуитивно аффинное преобразование отвечает за то, как модель "перевзвешивает" признаки и сдвигает результат в нужную область пространства.

#### Attention-механизм

Attention-механизм – это способ позволить модели избирательно "обращать внимание" на разные части входных данных в зависимости от контекста задачи.

Идея "внимания" состоит в том, что не все элементы входа одинаково важны. Для каждого элемента модель вычисляет, насколько сильно он связан с текущим запросом, и на основе этого взвешивает вклад информации.

В математической форме attention строится вокруг скалярных произведений. Для каждого элемента вычисляются три вектора:

* Query (Q) – что мы сейчас ищем
* Key (K) – что представляет каждый элемент
* Value (V) – какую информацию он несет

Оценка важности обычно вычисляется как скалярное произведение $$Q \cdot K$$, после чего применяется нормализация (чаще всего softmax). Итоговый результат – это взвешенная сумма векторов $$V$$.

Attention-механизмы лежат в основе трансформеров и современных языковых моделей. Они позволяют учитывать зависимости между словами независимо от расстояния в тексте, что принципиально отличает их от классических последовательных моделей.

Интуитивно attention можно представить как динамический механизм фокуса: модель каждый раз по-новому решает, какие части входа важны именно сейчас. С практической точки зрения attention – это обобщение идеи сходства векторов, доведенное до масштаба целых моделей.

#### Bag-of-Words (мешок слов)

Bag-of-Words (BoW) – это способ представить текст в виде числового вектора. Каждый элемент вектора соответствует слову из словаря, а значение показывает, сколько раз это слово встретилось в тексте.

При этом порядок слов полностью игнорируется. Фразы "PHP любит ML" и "ML любит PHP" будут иметь одинаковое представление.

BoW прост, быстр и хорошо подходит для первых экспериментов, но плохо передает смысл и контекст.

#### Bias (смещение)

Bias – это свободный член модели, позволяющий сдвигать результат независимо от входных признаков. В линейной регрессии bias соответствует члену $$b$$ в формуле

$$
y = wx + b
$$

Интуитивно bias отвечает за “базовый уровень” предсказания.

#### Cosine Similarity (косинусное сходство)

Cosine similarity – мера сходства двух векторов, основанная на косинусе угла между ними:

$$
cos(\theta) = \frac{A \cdot B}{|A||B|}
$$

Она показывает, насколько два вектора направлены в одну сторону, игнорируя их длину. Это особенно важно при работе с текстами, эмбеддингами и TF-IDF.

Cosine similarity часто предпочтительнее евклидова расстояния для текстов, потому что нас интересует не абсолютный масштаб, а смысловое направление.

#### Вектор

Вектор – упорядоченный набор чисел, представляющий объект. В машинном обучении почти все является вектором: строка текста, пользователь, событие, изображение.

Работа с векторами – фундамент ML.

#### Данные

Данные – это наблюдения, представленные в числовой форме. В контексте машинного обучения данные почти всегда интерпретируются как точки в многомерном пространстве, где каждая координата – это признак.

Тексты, изображения, события, пользователи – все в итоге сводится к векторам чисел.

#### Dot product (скалярное произведение)

Скалярное произведение – это операция над двумя векторами, результатом которой является одно число. В координатной форме оно определяется как сумма произведений соответствующих компонент:

$$
A \cdot B = \sum_i A_i B_i
$$

Геометрически скалярное произведение выражается через длины векторов и угол между ними:

$$
A \cdot B = |A| |B| \cos(\theta)
$$

Из этой формулы напрямую следует cosine similarity, которая по сути является нормированным скалярным произведением.

В машинном обучении скалярное произведение встречается повсюду. Линейная модель вычисляет предсказание как скалярное произведение вектора признаков и вектора весов с добавлением bias. Поиск похожих объектов, работа с эмбеддингами, TF-IDF и Bag-of-Words также сводятся к скалярным произведениям между векторами.

Интуитивно скалярное произведение отвечает на вопрос: "Насколько два вектора смотрят в одну сторону?" Если оно большое и положительное, объекты похожи; если близко к нулю – почти независимы; если отрицательное – направлены в разные стороны.

С практической точки зрения скалярное произведение – это базовая операция, вокруг которой построена большая часть классических и современных алгоритмов машинного обучения.

#### Embeddings (эмбеддинги)

Эмбеддинги – это плотные векторные представления объектов (слов, предложений, документов, изображений), которые кодируют их смысл.

В отличие от Bag-of-Words, эмбеддинги:

– имеют фиксированную размерность

– учитывают семантику

– позволяют сравнивать смысл, а не просто совпадение слов

Современные эмбеддинги обычно получаются с помощью нейросетей и активно используются в поиске, рекомендациях и RAG-системах.

#### Евклидово расстояние

Евклидово расстояние – обычное расстояние “по линейке” между двумя точками:

$$
d(A, B) = \sqrt{\sum (A_i - B_i)^2}
$$

Оно хорошо работает для числовых данных, но часто уступает cosine similarity для текстов и эмбеддингов.

#### Feature (признак)

Признак – это измеримая характеристика объекта. Для квартиры это может быть площадь, для пользователя – возраст, для текста – частота слова или значение эмбеддинга.

Модель работает не с "реальными объектами", а с их признаками.

#### Feature Engineering

Feature engineering – процесс преобразования сырых данных в признаки, удобные для модели. Это может быть нормализация чисел, кодирование категорий, построение TF-IDF или генерация дополнительных признаков.

На практике качество признаков часто важнее выбора конкретного алгоритма.

#### Градиентный спуск

Градиентный спуск – алгоритм оптимизации, который подбирает параметры модели, двигаясь в сторону уменьшения ошибки.

Он основан на вычислении производной (градиента) функции ошибки по параметрам модели и является базовым инструментом для линейных моделей и нейросетей.

#### Лемматизация

Лемматизация – это приведение слов к их базовой, словарной форме (лемме).

Например:

"бежал", "бегу", "бегут" → "бежать"

"книги", "книгой", "книгах" → "книга"

В отличие от простого стемминга, лемматизация учитывает морфологию и часть речи, поэтому результат обычно более корректен с точки зрения языка.

В задачах машинного обучения лемматизация используется как этап предобработки текста перед Bag-of-Words, TF-IDF или обучением моделей. Она уменьшает размер словаря и помогает модели лучше обобщать смысл, а не формы слов.

#### L1-регуляризация

L1-регуляризация – это регуляризация, основанная на сумме абсолютных значений весов модели:

$$
\text{Loss} = \text{Loss}_{\text{data}} + \lambda \sum |w_i|
$$

Ее ключевая особенность в том, что она стремится обнулять некоторые коэффициенты полностью. В результате модель начинает использовать только часть признаков, а остальные фактически отбрасывает.

С практической точки зрения L1-регуляризация выполняет неявный отбор признаков и особенно полезна в задачах с большим количеством признаков, например при использовании Bag-of-Words или TF-IDF.

Из-за этой особенности оптимизация с L1-регуляризацией сложнее, чем с L2, но итоговая модель часто получается более интерпретируемой.

#### L2-регуляризация

L2-регуляризация – это способ борьбы с переобучением, при котором модель штрафуется за слишком большие значения параметров.

Идея проста: если коэффициенты модели становятся слишком большими, значит она начинает слишком точно подгоняться под обучающие данные. L2-регуляризация добавляет к функции ошибки дополнительный член, зависящий от квадратов весов:

$$
\text{Loss} = \text{Loss}_{\text{data}} + \lambda \sum w_i^2
$$

Здесь $$\lambda$$ – коэффициент регуляризации, определяющий силу штрафа.

Интуитивно L2-регуляризация "размазывает" влияние признаков, заставляя модель использовать их более равномерно. Коэффициенты обычно становятся маленькими, но редко обнуляются полностью.

L2-регуляризация особенно хорошо работает в линейных моделях и логистической регрессии, когда признаки коррелированы между собой.

#### Loss-функция

Loss-функция измеряет, насколько плохо модель предсказывает результат на конкретном примере. Примеры:

– MSE для регрессии

– log loss для классификации

Минимизация loss-функции – центральная задача обучения модели.

#### Модель

Модель – это математическая функция с параметрами, которая аппроксимирует зависимость между входными данными и результатом.

Примеры:

– линейная регрессия

– логистическая регрессия

– нейросеть

Модель не "знает" мир – она лишь приближает его на основе данных.

#### Нормализация

Нормализация – приведение признаков к сопоставимому масштабу. Например, значения в диапазон \[0, 1] или с нулевым средним и единичной дисперсией.

Без нормализации многие алгоритмы обучаются хуже или нестабильно.

#### One-hot encoding

One-hot encoding – это способ кодирования категориальных признаков в числовой вид с помощью бинарных векторов.

Каждой категории соответствует отдельная координата вектора. Для конкретного объекта ровно одна координата равна 1, а все остальные равны 0.

Например, признак "цвет" со значениями {красный, зеленый, синий} может быть закодирован так:

красный → \[1, 0, 0]

зеленый → \[0, 1, 0]

синий → \[0, 0, 1]

One-hot encoding широко используется в линейных моделях, логистической регрессии и нейросетях, когда категории не имеют естественного порядка.

Главный недостаток one-hot encoding – рост размерности признакового пространства при большом количестве категорий. В текстовых задачах Bag-of-Words и TF-IDF по сути являются частным случаем one-hot представления, взвешенного по частоте.

В более сложных моделях и при большом числе категорий one-hot encoding часто заменяют эмбеддингами, которые позволяют компактно представить категориальные данные и учитывать скрытые связи между ними.

#### Переобучение (Overfitting)

Переобучение возникает, когда модель слишком хорошо запоминает обучающие данные, но плохо обобщает на новые.

Обычно это следствие слишком сложной модели или недостатка данных.

#### Пространство признаков

Пространство признаков – это абстрактное пространство, в котором каждая ось соответствует одному признаку, а каждый объект – точка в этом пространстве.

Именно в этом пространстве мы считаем расстояния, углы и сходство.

#### Стемминг

Стемминг – это упрощенный способ приведения слов к общей основе (стему) путем механического отсечения окончаний и суффиксов.

Например:

"бегу”, "бежал", "бегущий" → "бег"

"connection", "connected", "connecting" → "connect"

В отличие от лемматизации, стемминг:

– не опирается на словари и грамматику

– работает быстрее

– может порождать формы, которые не являются реальными словами

Стемминг часто используется как быстрый этап предобработки текста перед Bag-of-Words или TF-IDF, особенно в задачах, где точная языковая форма менее важна, чем общая тема документа.

Недостаток стемминга в том, что он может объединять слова с разным смыслом или, наоборот, не объединять близкие по значению формы. Поэтому в более точных системах, особенно для сложных языков, чаще предпочитают лемматизацию.

В практическом смысле выбор между стеммингом и лемматизацией – это компромисс между скоростью, простотой и качеством смыслового представления текста.

#### Стоп-слова

Стоп-слова – это часто встречающиеся слова, которые обычно несут мало смысловой нагрузки: "и", "в", "на", "это", "the", "is" и т.д.

При анализе текста такие слова часто удаляют, чтобы:

– уменьшить размерность признаков

– снизить шум

– сосредоточиться на содержательных словах

Стоп-слова особенно актуальны при использовании Bag-of-Words и TF-IDF. Однако при работе с современными эмбеддингами и нейросетями их удаление не всегда необходимо и иногда даже вредно, поскольку модель может использовать контекст, в том числе служебные слова.

#### TF-IDF

TF-IDF (Term Frequency – Inverse Document Frequency) – улучшенная версия Bag-of-Words, которая учитывает не только частоту слова в документе, но и его редкость во всей коллекции.

Редкие, но информативные слова получают больший вес, чем частые служебные.

TF-IDF часто используется как базовое представление текста перед классификацией или поиском.

#### Train / Test split

Train/Test split – разделение данных на обучающую и тестовую выборки. Модель обучается на одной части данных и проверяется на другой.

Это позволяет оценить, насколько хорошо модель обобщает знания.
