# Кейс 1: MSE и цена большого промаха

#### Прогноз цены и влияние выбросов (MSE на практике)

Начнём с простого и очень жизненного примера. Представим сервис оценки стоимости квартир. Ничего сложного: на вход подаётся площадь, на выходе – прогнозируемая цена. Это типичная задача регрессии, и для неё почти автоматически выбирают [MSE](../../../vvedenie/glossarii.md#mse-mean-squared-error).

Но именно здесь хорошо видно, какую цену мы платим за такой выбор.

#### **Цель кейса**

Показать, как MSE резко реагирует на выбросы и почему одна плохая точка может испортить модель.

#### **Сценарий**

У нас есть несколько квартир с известной реальной ценой и предсказаниями модели. Для простоты будем считать, что модель уже обучена, а мы лишь оцениваем качество её работы.

Реальные цены (в условных единицах):

```php
$y = [100, 120, 130, 115, 125];
```

Предсказания модели:

```php
$yHat = [102, 118, 128, 117, 123];
```

Ошибки есть, но они небольшие. Это выглядит как вполне адекватная модель.

#### **Напоминание: как считается MSE**

Реализуем MSE буквально в несколько строк, без каких-либо библиотек:

```php
function mse(array $y, array $yHat): float {
    $n = count($y);
    $sum = 0.0;

    for ($i = 0; $i < $n; $i++) {
        $diff = $y[$i] - $yHat[$i];
        $sum += $diff * $diff;
    }

    return $sum / $n;
}

echo mse($y, $yHat);
```

Посчитаем ошибку:

```php
echo mse($y, $yHat) . PHP_EOL;
```

Значение MSE получается небольшим. Это ожидаемо: все ошибки лежат в пределах нескольких единиц, и квадрат не делает их катастрофическими.

#### **Добавляем одну "плохую" квартиру**

Теперь испортим картину всего одной точкой. Пусть в данных появилась странная квартира: либо ошибка в базе, либо уникальный объект, либо просто неудачный прогноз.&#x20;

Добавим выброс.

Реальная цена:

```php
$y[] = 300;
```

Предсказание модели:

```php
$yHat[] = 130;
```

Ошибка здесь огромная. Посчитаем MSE снова:

```php
echo mse($y, $yHat);
```

И вот тут происходит ключевой момент кейса.

#### **Что мы видим**

MSE вырос не просто заметно, а непропорционально сильно. Хотя новых данных всего одна точка, именно она начинает доминировать над всей функцией потерь.

Почему так происходит, легко увидеть на уровне одной формулы:

$$
(300 - 130)^2 = 170^2 = 28900
$$

Для сравнения, все предыдущие ошибки давали квадраты порядка единиц или десятков. Один промах буквально "перекрикивает" все остальные наблюдения.

#### **Почему это не баг**

Очень важно понять: такое поведение MSE – осознанное свойство, а не ошибка дизайна.

Используя квадратичную ошибку, мы заранее говорим модели:

> Большие промахи гораздо хуже, чем много маленьких.

Это разумно во многих задачах. Например:

* в прогнозе цен для банка
* в расчётах рисков
* в инженерных и физических моделях

Там один крупный промах может стоить дороже, чем десяток мелких неточностей.

#### **Но за это есть цена**

Обратная сторона очевидна. Если в данных есть:

* выбросы
* ошибки разметки
* редкие, но экстремальные значения

MSE начинает подстраивать модель именно под них. Иногда в ущерб большинству "нормальных" данных.

Этот кейс важен не потому, что MSE плох. А потому, что он ясно показывает: loss-функция – это выбор приоритетов.

#### **Ключевой вывод**

MSE не просто измеряет ошибку. Он задаёт модельному обучению философию:

* большие ошибки недопустимы
* выбросы имеют решающее значение
* стабильность достигается ценой чувствительности

В следующих кейсах мы увидим, как эти же идеи проявляются при сравнении моделей и почему для классификации такая логика уже не работает.
