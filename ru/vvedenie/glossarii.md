# Глоссарий

Эта глава служит опорной точкой. Сюда можно возвращаться, если термин встречается в коде, формуле или описании алгоритма и хочется быстро освежить смысл без погружения в теорию.

#### Accuracy (точность классификации)

Accuracy – это доля правильных предсказаний модели от общего числа предсказаний. Проще говоря, это ответ на вопрос: "В скольких случаях модель угадала"?

Формально accuracy считается как отношение числа верных ответов к общему числу примеров.

Accuracy удобна, потому что:

* легко считается
* легко интерпретируется
* интуитивно понятна

Но у неё есть важное ограничение: accuracy может вводить в заблуждение при несбалансированных данных. Например, если 95% объектов принадлежат одному классу, модель может показывать 95% accuracy, просто всегда предсказывая этот класс.

Поэтому accuracy часто используют:

* как базовую метрику
* для первичной оценки модели
* вместе с другими метриками (loss, precision, recall)

Интуитивный смысл accuracy такой: "Процент случаев, где модель не ошиблась". В контексте машинного обучения важно помнить: высокая accuracy не всегда означает хорошую модель.

#### Алгоритм

Алгоритм – это конечная последовательность шагов, которая преобразует входные данные в результат. В машинном обучении алгоритм обычно определяет, как именно мы подбираем параметры модели: например, градиентный спуск, стохастический градиентный спуск или \
$$k$$-ближайших соседей.

Важно различать модель и алгоритм: модель – это форма зависимости, алгоритм – способ ее обучения или применения.

#### Априорная и апостериорная вероятность

Априорная вероятность – это вероятность события _до_ учёта новых данных.

Апостериорная вероятность – это вероятность события _после_ учёта новых данных.

Идея происходит из байесовского подхода. Априорная вероятность отражает наше исходное знание или предположение. Апостериорная вероятность – это обновлённая оценка после получения информации.&#x20;

Связь между ними описывает формула Байеса:&#x20;

апостериорная ∝ правдоподобие × априорная

Проще говоря:

новая уверенность = старая уверенность + влияние наблюдений

Пример:

Если известно, что 1% писем – спам (априорная вероятность), и письмо содержит характерные признаки спама, то после учёта этих признаков вероятность того, что это спам, увеличится – это уже апостериорная вероятность.

В машинном обучении эти понятия используются:

* в наивном Байесе
* в байесовских моделях
* в задачах оценки неопределённости
* в probabilistic-подходах

Интуитивно:

априорная вероятность – "что мы думали заранее"

апостериорная вероятность – "что мы думаем после того, как увидели данные"

Этот термин логично связывает MLE, вероятностные модели и обновление знаний в процессе обучения.

#### Аффинное преобразование

Аффинное преобразование – это преобразование вида

$$
y = Wx + b
$$

где $$W$$ – матрица весов, $$x$$  – входной вектор признаков, а $$b$$ – вектор смещений (bias).

Геометрически аффинное преобразование сочетает в себе линейное преобразование (повороты, растяжения, сжатия, отражения) и сдвиг. В отличие от чисто линейного преобразования, оно не обязано сохранять начало координат.

В машинном обучении аффинное преобразование лежит в основе большинства моделей:

* линейной и логистической регрессии
* полносвязных слоев нейросетей
* преобразования эмбеддингов и признаков

Практически любая модель сначала выполняет аффинное преобразование входных данных, а затем применяет нелинейность или функцию решения. Поэтому выражение $$Wx + b$$ можно считать фундаментальным строительным блоком современного ML.

Интуитивно аффинное преобразование отвечает за то, как модель "перевзвешивает" признаки и сдвигает результат в нужную область пространства.

#### Attention-механизм

Attention-механизм – это способ позволить модели избирательно "обращать внимание" на разные части входных данных в зависимости от контекста задачи.

Идея "внимания" состоит в том, что не все элементы входа одинаково важны. Для каждого элемента модель вычисляет, насколько сильно он связан с текущим запросом, и на основе этого взвешивает вклад информации.

В математической форме attention строится вокруг скалярных произведений. Для каждого элемента вычисляются три вектора:

* Query (Q) – что мы сейчас ищем
* Key (K) – что представляет каждый элемент
* Value (V) – какую информацию он несет

Оценка важности обычно вычисляется как скалярное произведение $$Q \cdot K$$, после чего применяется нормализация (чаще всего softmax). Итоговый результат – это взвешенная сумма векторов $$V$$.

Attention-механизмы лежат в основе трансформеров и современных языковых моделей. Они позволяют учитывать зависимости между словами независимо от расстояния в тексте, что принципиально отличает их от классических последовательных моделей.

Интуитивно attention можно представить как динамический механизм фокуса: модель каждый раз по-новому решает, какие части входа важны именно сейчас. С практической точки зрения attention – это обобщение идеи сходства векторов, доведенное до масштаба целых моделей.

#### Auto-scaling

Auto-scaling – это механизм автоматического изменения вычислительных ресурсов системы в зависимости от нагрузки.

В контексте ML auto-scaling применяется к:

* сервисам инференса моделей
* пайплайнам обработки данных
* системам обучения и переобучения моделей

Когда количество запросов растет, система автоматически добавляет вычислительные ресурсы; при снижении нагрузки – освобождает их. Это позволяет поддерживать стабильное время ответа и оптимизировать стоимость инфраструктуры.

С практической точки зрения auto-scaling важен не для самой модели, а для ее жизненного цикла в реальной системе: даже хорошая модель становится бесполезной, если не выдерживает нагрузку.

#### Backpropagation (обратное распространение ошибки)

Backpropagation, или backprop – это алгоритм вычисления градиентов функции ошибки по параметрам нейросети путем последовательного применения правила цепочки от выхода модели к ее входам.

Идея backprop заключается в том, что ошибка, вычисленная на выходе сети, распространяется назад по слоям, позволяя определить вклад каждого параметра в итоговую ошибку.

Математически backprop основан на правиле цепочки производных. Каждый слой получает градиент от следующего слоя, умножает его на свою локальную производную и передает дальше назад.

Backprop не является отдельным алгоритмом обучения, а служит механизмом вычисления градиентов. Сами параметры обновляются уже с помощью градиентного спуска, SGD или их вариантов.

В практическом смысле backprop делает возможным обучение многослойных моделей. Без него вычисление градиентов для нейросетей было бы вычислительно непрактичным.

Интуитивно backprop можно представить как пошаговый разбор ошибки: модель выясняет, какой именно слой и какие веса ответственны за неправильное предсказание, и корректирует их.

#### Bag-of-Words (мешок слов)

Bag-of-Words (BoW) – это способ представить текст в виде числового вектора. Каждый элемент вектора соответствует слову из словаря, а значение показывает, сколько раз это слово встретилось в тексте.

При этом порядок слов полностью игнорируется. Фразы "PHP любит ML" и "ML любит PHP" будут иметь одинаковое представление.

BoW прост, быстр и хорошо подходит для первых экспериментов, но плохо передает смысл и контекст.

#### Base rate neglect (игнорирование базовой частоты)

Base rate neglect – это ошибка мышления, при которой игнорируется априорная вероятность события (базовая частота) и внимание сосредотачивается только на новых признаках или симптомах.

Проще говоря, это ситуация, когда человек или модель забывает учитывать, насколько событие вообще редкое.

Пример:

Если болезнь встречается у 1% населения, а тест показывает 95% точность, многие переоценивают вероятность болезни при положительном результате. На практике без учёта базовой частоты итоговая вероятность может оказаться значительно ниже ожидаемой.

В машинном обучении base rate neglect проявляется, когда:

* игнорируется дисбаланс классов
* не учитывается априорная вероятность
* модель оценивается только по accuracy
* забывают про распределение данных

Этот эффект напрямую связан с:

* априорной и апостериорной вероятностью
* формулой Байеса
* калибровкой вероятностей

Интуитивно base rate neglect – это ошибка вида:

"Признаки выглядят убедительно, значит событие почти наверняка произошло", хотя само событие может быть крайне редким.

В практических задачах игнорирование базовой частоты может приводить к переоценке рисков, неверным решениям и плохой интерпретации результатов модели.

#### Batch gradient descent

Batch gradient descent – это классический вариант градиентного спуска, при котором градиент функции ошибки вычисляется по всей обучающей выборке целиком перед каждым обновлением параметров модели.

На каждом шаге алгоритм использует все доступные данные, поэтому направление градиента является точным для текущей модели. Это делает траекторию обучения гладкой и стабильной.

Основные особенности batch gradient descent:

* стабильные и предсказуемые обновления
* отсутствие шума в градиенте
* высокая вычислительная стоимость на больших датасетах

Из-за необходимости проходить по всем данным на каждом шаге batch gradient descent плохо масштабируется и редко используется в чистом виде для больших задач.

С практической точки зрения batch gradient descent удобно применять:

* на небольших наборах данных
* в учебных и аналитических примерах
* когда важна воспроизводимость и точность шага

В реальных системах его часто заменяют mini-batch или стохастическим градиентным спуском, которые обеспечивают лучший баланс между скоростью и устойчивостью обучения.

#### Bayesian updating (байесовское обновление)

Байесовское обновление – это процесс пересчёта вероятности гипотезы при появлении новых данных.

Идея проста: мы начинаем с априорной вероятности (нашего первоначального предположения), затем получаем наблюдения и обновляем свою уверенность, получая апостериорную вероятность.

Схематично:

новая вероятность = старая вероятность × влияние данных

Формально это выражается через формулу Байеса, но концептуально всё сводится к постепенному уточнению знаний по мере накопления информации.

Байесовское обновление используется:

* в наивном Байесе
* в байесовских моделях
* при оценке рисков
* в онлайн-обучении
* в системах, работающих с потоковыми данными

В отличие от классического подхода (где параметры просто подбираются), байесовский подход рассматривает параметры как случайные величины и обновляет распределение их вероятностей.

Интуитивно байесовское обновление – это правило: "Не начинать с нуля, а корректировать свою уверенность шаг за шагом".

В практическом ML это важно, когда данные поступают постепенно, распределение меняется или необходимо явно учитывать неопределённость модели.

#### Bernoulli Naive Bayes

Bernoulli Naive Bayes – это разновидность наивного Байеса, предназначенная для бинарных признаков.

В этой модели каждый признак принимает только два значения: есть / нет, 1 / 0, присутствует / отсутствует.

Чаще всего Bernoulli Naive Bayes используется в задачах классификации текста, где признак показывает, встречается ли слово в документе, а не сколько раз оно встречается.

Главная идея:

* модель оценивает вероятность наличия признака при каждом классе
* предполагается независимость признаков
* итоговая вероятность класса считается через произведение вероятностей

Bernoulli Naive Bayes хорошо работает, когда:

* важен сам факт появления слова
* данные разреженные
* используется бинарное представление (bag-of-words без частот)

Отличие от Multinomial Naive Bayes:

* Bernoulli учитывает только присутствие признака
* Multinomial учитывает частоту появления

Интуитивно Bernoulli Naive Bayes отвечает на вопрос: "Набор каких признаков присутствует, и как это связано с классом?"

Эта модель простая, быстрая и часто служит хорошим базовым решением для текстовой классификации.

#### Bias (смещение)

Bias – это свободный член модели, позволяющий сдвигать результат независимо от входных признаков. В линейной регрессии bias соответствует члену $$b$$ в формуле

$$
y = wx + b
$$

Интуитивно bias отвечает за "базовый уровень" предсказания.

#### Bias–variance tradeoff

Bias–variance tradeoff (компромисс смещения и разброса) – это фундаментальное понятие в машинном обучении, описывающее баланс между простотой модели и её способностью обобщать данные.

Bias (смещение) – это ошибка, возникающая из-за слишком сильных упрощающих предположений модели.

Модель с высоким bias:

* слишком простая
* плохо подстраивается под данные
* приводит к недообучению (underfitting)

Variance (разброс) – это чувствительность модели к конкретной обучающей выборке.

Модель с высоким variance:

* слишком сложная
* хорошо запоминает обучающие данные
* плохо обобщает на новые данные
* приводит к переобучению (overfitting)

Общая ошибка модели складывается из:

* bias
* variance
* неизбежного шума в данных

Увеличение сложности модели обычно уменьшает bias, но увеличивает variance. Упрощение модели действует наоборот.

В машинном обучении управление bias–variance tradeoff осуществляется через:

* выбор модели
* регуляризацию (L1, L2)
* количество признаков
* размер обучающей выборки
* early stopping

Интуитивно bias–variance tradeoff – это поиск баланса между "слишком грубо" и "слишком точно для конкретных данных".

С практической точки зрения понимание bias–variance tradeoff важнее, чем знание отдельных алгоритмов, так как оно объясняет, _почему_ модель ведёт себя так, как она себя ведёт.

#### Cold start (проблема холодного старта в рекомендациях)

Cold start – это ситуация в рекомендательных системах, когда модели не хватает данных, чтобы делать хорошие рекомендации.

Чаще всего это происходит в двух случаях:

* новый пользователь, про которого ещё ничего не известно
* новый объект (товар, статья, видео), у которого нет истории взаимодействий

Проблема в том, что классические рекомендательные модели опираются на прошлое поведение. Если прошлого нет, модель "не знает", на что опираться.

Типичные способы смягчить cold start:

* использовать контентные признаки (описание товара, текст, категории)
* задавать начальные предпочтения пользователя
* показывать популярные или универсальные объекты
* комбинировать разные подходы (гибридные модели)

Cold start подчёркивает важную мысль: качество рекомендаций зависит не только от алгоритма, но и от доступных данных и их структуры.

Интуитивно это выглядит так: "Нельзя рекомендовать по вкусу, если ещё не знаешь вкусы клиента".

#### Concept drift

Concept drift – это изменение статистических свойств данных со временем, при котором связь между признаками и целевой переменной перестает быть прежней.

Проще говоря, модель продолжает работать, но реальность уже изменилась.

Примеры concept drift:

* изменение поведения пользователей
* сезонные эффекты
* появление новых типов данных
* изменения рынка или внешних условий

Concept drift не является ошибкой модели – это естественное свойство живых систем. Для борьбы с ним используют мониторинг качества, переобучение, скользящие окна данных и онлайн-обучение.

Интуитивно concept drift – это момент, когда модель "осталась в прошлом".

#### Cosine Similarity (косинусное сходство)

Cosine similarity – мера сходства двух векторов, основанная на косинусе угла между ними:

$$
cos(\theta) = \frac{A \cdot B}{|A||B|}
$$

Она показывает, насколько два вектора направлены в одну сторону, игнорируя их длину. Это особенно важно при работе с текстами, эмбеддингами и TF-IDF.

Cosine similarity часто предпочтительнее евклидова расстояния для текстов, потому что нас интересует не абсолютный масштаб, а смысловое направление.

#### Вектор

Вектор – упорядоченный набор чисел, представляющий объект. В машинном обучении почти все является вектором: строка текста, пользователь, событие, изображение.

Работа с векторами – фундамент ML.

#### Decision boundary (граница принятия решения)

Decision boundary – это граница в пространстве признаков, которая разделяет разные классы.

Проще говоря, это линия (в 2D), поверхность (в 3D) или гиперплоскость (в более высокой размерности), по одну сторону которой модель относит объекты к одному классу, а по другую – к другому.

Разные модели создают разные границы:

* линейная регрессия и логистическая регрессия → линейная граница
* k-NN → сложная, "ломаная" граница
* деревья решений → ступенчатая, осевая граница
* нейросети → могут формировать очень сложные нелинейные границы

Сложность decision boundary напрямую связана с bias–variance tradeoff:

* слишком простая граница → underfitting
* слишком сложная → overfitting

Интуитивно decision boundary отвечает на вопрос: "Где проходит линия между классами?"

В машинном обучении важно понимать, что обучение модели – это фактически поиск подходящей границы разделения в пространстве признаков.

#### Dot product (скалярное произведение)

Скалярное произведение – это операция над двумя векторами, результатом которой является одно число. В координатной форме оно определяется как сумма произведений соответствующих компонент:

$$
A \cdot B = \sum_i A_i B_i
$$

Геометрически скалярное произведение выражается через длины векторов и угол между ними:

$$
A \cdot B = |A| |B| \cos(\theta)
$$

Из этой формулы напрямую следует cosine similarity, которая по сути является нормированным скалярным произведением.

В машинном обучении скалярное произведение встречается повсюду. Линейная модель вычисляет предсказание как скалярное произведение вектора признаков и вектора весов с добавлением bias. Поиск похожих объектов, работа с эмбеддингами, TF-IDF и Bag-of-Words также сводятся к скалярным произведениям между векторами.

Интуитивно скалярное произведение отвечает на вопрос: "Насколько два вектора смотрят в одну сторону?" Если оно большое и положительное, объекты похожи; если близко к нулю – почти независимы; если отрицательное – направлены в разные стороны.

С практической точки зрения скалярное произведение – это базовая операция, вокруг которой построена большая часть классических и современных алгоритмов машинного обучения.

#### Данные

Данные – это наблюдения, представленные в числовой форме. В контексте машинного обучения данные почти всегда интерпретируются как точки в многомерном пространстве, где каждая координата – это признак.

Тексты, изображения, события, пользователи – все в итоге сводится к векторам чисел.

#### Embeddings (эмбеддинги)

Эмбеддинги – это плотные векторные представления объектов (слов, предложений, документов, изображений), которые кодируют их смысл.

В отличие от Bag-of-Words, эмбеддинги:

* имеют фиксированную размерность
* учитывают семантику
* позволяют сравнивать смысл, а не просто совпадение слов

Современные эмбеддинги обычно получаются с помощью нейросетей и активно используются в поиске, рекомендациях и RAG-системах.

#### Epoch (эпоха)

Эпоха – это один полный проход алгоритма обучения по всей обучающей выборке.

Если используется batch gradient descent, одна эпоха соответствует одному обновлению параметров модели. При стохастическом или mini-batch градиентном спуске в течение одной эпохи выполняется много обновлений – по одному на каждый объект или батч данных.

Количество эпох определяет, сколько раз модель "увидит" все обучающие данные. Слишком малое число эпох приводит к недообучению, а слишком большое – к переобучению.

На практике число эпох выбирают исходя из:

* поведения loss-функции
* качества на валидационной выборке
* скорости сходимости

Интуитивно эпоху можно представить как один учебный цикл, в течение которого модель последовательно знакомится со всеми примерами и постепенно корректирует свои параметры.

#### Евклидово расстояние

Евклидово расстояние – обычное расстояние “по линейке” между двумя точками:

$$
d(A, B) = \sqrt{\sum (A_i - B_i)^2}
$$

Оно хорошо работает для числовых данных, но часто уступает cosine similarity для текстов и эмбеддингов.

#### Feature (признак)

Признак – это измеримая характеристика объекта. Для квартиры это может быть площадь, для пользователя – возраст, для текста – частота слова или значение эмбеддинга.

Модель работает не с "реальными объектами", а с их признаками.

#### Feature engineering

Feature engineering – это процесс преобразования сырых данных в признаки, с которыми модель может эффективно работать.

Модель сама по себе не понимает тексты, события, пользователей или числа в реальном мире. Она оперирует только векторами признаков. Feature engineering отвечает за то, какими именно будут эти векторы.

К feature engineering относятся:

* нормализация и масштабирование числовых данных
* кодирование категориальных признаков (one-hot encoding, target encoding)
* обработка текста (стоп-слова, стемминг, лемматизация, TF-IDF, эмбеддинги)
* генерация новых признаков из существующих
* агрегации, временные окна, счетчики и флаги

Качество feature engineering часто оказывает большее влияние на результат, чем выбор конкретного алгоритма. Простая модель с хорошими признаками нередко превосходит сложную модель с плохими.

Интуитивно feature engineering – это процесс перевода реальности на язык, понятный модели.

С практической точки зрения feature engineering – ключевая компетенция в прикладном ML, особенно при работе с ограниченными данными и классическими алгоритмами.

#### Gini impurity (индекс Джини)

Gini impurity – это мера "нечистоты" набора данных, используемая в деревьях решений для оценки качества разбиения.&#x20;

Она показывает, насколько вероятно случайно ошибиться в классификации, если выбирать класс объекта случайно согласно распределению классов в узле.  Если в узле все объекты одного класса – Gini impurity равен нулю (узел "чистый"). Если классы распределены равномерно – значение выше (узел "грязный").

В деревьях решений Gini используется для:

* выбора признака для разбиения
* оценки качества разделения
* построения структуры дерева

Интуитивно Gini impurity отвечает на вопрос: "Насколько смешаны классы в этой группе?"

Gini impurity похож на энтропию, но:

* вычисляется проще
* работает быстрее
* чаще используется в практических реализациях (например, в CART)

В контексте логики энтропии Gini impurity – это альтернативный способ измерять неопределённость и чистоту разбиения.

#### Гауссовское распределение

Гауссовское распределение (нормальное распределение) – это одно из самых важных распределений вероятности в статистике и машинном обучении.

Оно описывается двумя параметрами:

* средним значением $$\mu$$
* дисперсией $$\sigma^2$$

Плотность вероятности имеет вид:

$$
p(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)
$$

Геометрически гауссовское распределение имеет форму "колокола": значения, близкие к среднему, встречаются чаще, а вероятность больших отклонений быстро убывает.

В машинном обучении гауссовское распределение часто используется как модель шума в данных. Например, при линейной регрессии обычно предполагают, что ошибка предсказания распределена нормально. Именно это предположение приводит к MSE как оптимальной loss-функции при MLE.

Гауссовское распределение также лежит в основе:

* вероятностных моделей
* байесовских методов
* нормализации признаков
* инициализации весов нейросетей

Интуитивно гауссовское распределение – это математический способ сказать: "малые ошибки встречаются часто, большие – редко".

#### Градиент

Градиент – это вектор производных функции по всем ее параметрам. Он указывает направление наибольшего роста функции в многомерном пространстве.

Если функция зависит от параметров $$w_1, w_2, \dots, w_n$$, то градиент записывается как:

$$
\nabla f = \left( \frac{\partial f}{\partial w_1}, \frac{\partial f}{\partial w_2}, \dots, \frac{\partial f}{\partial w_n} \right)
$$

Геометрически градиент перпендикулярен линиям равного значения функции и показывает, куда "идет вверх" поверхность ошибки. Поэтому для минимизации функции (например, loss-функции) двигаются в противоположном направлении – против градиента.

В машинном обучении градиент используется для:

* обновления параметров модели
* обучения линейных моделей и нейросетей
* оптимизации MSE, log loss и других функций

Интуитивно градиент отвечает на вопрос: "В какую сторону нужно изменить параметры, чтобы ошибка росла быстрее всего?" А значит, двигаясь в обратную сторону, мы быстрее всего уменьшаем ошибку.

С практической точки зрения почти все обучение моделей сводится к вычислению градиентов и небольшим шагам в пространстве параметров.

#### Градиентный спуск

Градиентный спуск – алгоритм оптимизации, который подбирает параметры модели, двигаясь в сторону уменьшения ошибки.

Он основан на вычислении производной (градиента) функции ошибки по параметрам модели и является базовым инструментом для линейных моделей и нейросетей.

#### Information Gain (прирост информации)

Information Gain – это мера того, насколько признак помогает уменьшить неопределённость в данных.

Идея простая: хороший признак – тот, после которого становится легче понять, к какому классу относится объект.

Формально Information Gain показывает, насколько уменьшается энтропия после разбиения данных по признаку:

$$
IG = H(до) - H(после)
$$

Если после разбиения данные стали более "чистыми" (в каждом поднаборе в основном один класс), то прирост информации большой. Если разбиение почти ничего не меняет, прирост близок к нулю.

Information Gain используется:

* в деревьях решений
* при выборе признаков
* для объяснимости модели

Интуитивный вопрос, на который он отвечает: "Насколько этот вопрос приближает нас к правильному ответу?"

Важно помнить, что Information Gain может переоценивать признаки с большим числом уникальных значений. Поэтому на практике часто используют его модификации, например Gain Ratio.

В контексте всей книги Information Gain хорошо связывает идеи энтропии, деревьев решений и интерпретируемости моделей.

#### Инференс (Inference)

Инференс – это этап работы модели, когда она уже обучена и используется для получения предсказаний на новых данных.

Если обучение отвечает на вопрос "как настроить параметры модели", то инференс отвечает на вопрос "что модель думает сейчас". На этом этапе веса не меняются, градиенты не считаются, модель просто применяет выученные преобразования.

В машинном обучении инференс включает:

* подготовку входных данных
* прямой проход через модель
* получение вероятностей или предсказаний

Инференс может происходить:

* в реальном времени (онлайн)
* пакетно (batch)
* на сервере, на устройстве пользователя или на edge-устройствах

С практической точки зрения инференс часто важнее обучения. Именно он определяет скорость, задержки, стоимость и масштабируемость системы.

Интуитивно инференс – это момент, когда модель перестаёт "учиться" и начинает "работать".

#### к-NN (k-Nearest Neighbors, k-ближайших соседей)

k-NN – это алгоритм без обучения. Он ничего не считает заранее, а просто хранит все данные.

Когда появляется новый объект, мы:

1. Считаем расстояние от него до всех известных объектов
2. Берём k самых близких
3. Смотрим на их ответы

Для классификации выбираем класс, который встречается чаще всего среди соседей.

Для регрессии берём среднее значение.

Число k задаёт поведение модели. Малое k делает модель чувствительной к шуму. Большое k сглаживает решение, но может терять детали. Это наглядный пример компромисса bias–variance.

k-NN сильно зависит от расстояния и масштаба признаков. Если признаки не нормализованы, "близость" может быть обманчивой.

Алгоритм простой и понятный, но медленный при предсказании, потому что нужно сравнивать с большим числом точек. Поэтому k-NN часто используют как базовый ориентир или для объяснения идей, а не как финальное решение.

По сути, k-NN показывает: если объекты похожи в пространстве признаков, у них часто похожие ответы. Это вся идея.

#### Контекстные модели

Контекстные модели – это модели в NLP, которые учитывают окружение слова, а не рассматривают его изолированно.

В отличие от bag-of-words или TF-IDF, где слова считаются независимо, контекстные модели пытаются понять, _в каком смысле_ слово используется именно здесь.

Классический пример: русское слово "коса" или английское "bank".

В контекстной модели его представление будет разным в предложениях:

* "сельскохозяйственный инструмент" и "берег (коса земли)" или "элемент причёски"
* "the bank issued a loan" и "river bank"

Контекстные модели:

* строят разные векторные представления одного и того же слова
* учитывают порядок слов и их взаимосвязи
* работают с целыми предложениями и текстами

На практике контекст появляется через:

* n-граммы (частично)
* рекуррентные сети
* attention-механизмы
* трансформеры

Контекстные модели лежат в основе современных NLP-систем: поисковых движков, чат-ботов, систем суммаризации и вопросно-ответных моделей.

Интуитивно контекстная модель отвечает на вопрос: "Что именно означает это слово _здесь_, а не вообще?"

#### Кусочно-локальная аппроксимация

Кусочно-локальная аппроксимация – это способ моделирования сложной зависимости, при котором пространство признаков делится на области, и в каждой области строится простая модель.

Идея в том, что глобально зависимость может быть сложной, но локально она часто выглядит простой. Вместо одной сложной формулы мы используем несколько простых, каждая из которых работает на своём участке.

Примеры:

* деревья решений (разбивают пространство на прямоугольные области)
* локально-взвешенная регрессия
* k-NN (неявно формирует локальные области)
* сплайны

Плюсы:

* хорошо описывает нелинейные зависимости
* проще интерпретировать локальное поведение

Минусы:

* может создавать разрывы между областями
* чувствительна к способу разбиения
* при большом числе областей возрастает риск переобучения

Интуитивно кусочно-локальная аппроксимация – это подход: "В каждой части пространства действуют свои правила".

С точки зрения компромисса между смещением и дисперсией (bias–variance) такой подход уменьшает смещение (bias) по сравнению с глобальной моделью, но при слишком мелком разбиении увеличивает дисперсию (variance).

#### L1-регуляризация

L1-регуляризация – это регуляризация, основанная на сумме абсолютных значений весов модели:

$$
\text{Loss} = \text{Loss}_{\text{data}} + \lambda \sum |w_i|
$$

Ее ключевая особенность в том, что она стремится обнулять некоторые коэффициенты полностью. В результате модель начинает использовать только часть признаков, а остальные фактически отбрасывает.

С практической точки зрения L1-регуляризация выполняет неявный отбор признаков и особенно полезна в задачах с большим количеством признаков, например при использовании Bag-of-Words или TF-IDF.

Из-за этой особенности оптимизация с L1-регуляризацией сложнее, чем с L2, но итоговая модель часто получается более интерпретируемой.

#### L2-регуляризация

L2-регуляризация – это способ борьбы с переобучением, при котором модель штрафуется за слишком большие значения параметров.

Идея проста: если коэффициенты модели становятся слишком большими, значит она начинает слишком точно подгоняться под обучающие данные. L2-регуляризация добавляет к функции ошибки дополнительный член, зависящий от квадратов весов:

$$
\text{Loss} = \text{Loss}_{\text{data}} + \lambda \sum w_i^2
$$

Здесь $$\lambda$$ – коэффициент регуляризации, определяющий силу штрафа.

Интуитивно L2-регуляризация "размазывает" влияние признаков, заставляя модель использовать их более равномерно. Коэффициенты обычно становятся маленькими, но редко обнуляются полностью.

L2-регуляризация особенно хорошо работает в линейных моделях и логистической регрессии, когда признаки коррелированы между собой.

#### Laplace smoothing (сглаживание Лапласа)

Laplace smoothing – это техника сглаживания вероятностей, используемая для предотвращения нулевых вероятностей в вероятностных моделях.

Проблема возникает, когда некоторое событие ни разу не встречалось в обучающих данных. В таком случае его вероятность оценивается как ноль, что может полностью "сломать" модель. В наивном Байесе это особенно критично, так как вероятности перемножаются.

Сглаживание Лапласа решает эту проблему, добавляя небольшую константу (обычно 1) к каждому счетчику:

$$
P(x \mid y) = \frac{\text{count}(x, y) + 1}{\text{count}(y) + |V|}
$$

где $$|V|$$ – размер словаря или множества возможных значений признака.

Интуитивно Laplace smoothing означает: "Если мы чего-то не видели, это не значит, что этого не существует – просто мы видели это редко".

С практической точки зрения сглаживание Лапласа:

* делает модель устойчивой к редким событиям
* особенно важно для текстовых моделей (Bag-of-Words, TF-IDF)
* является стандартным элементом наивного Байеса

Laplace smoothing не улучшает модель за счет информации, но защищает ее от логических провалов, связанных с нулевыми вероятностями.

#### Learning rate (скорость обучения)

Learning rate – это коэффициент, определяющий размер шага, с которым модель изменяет свои параметры при движении против градиента.

В простейшем виде обновление параметров выглядит так:

$$
w := w - \eta \nabla L
$$

где $$\eta$$ – learning rate, а $$\nabla L$$ – градиент функции ошибки.

Интуитивно learning rate отвечает на вопрос: "Насколько смело мы делаем шаг в выбранном направлении?"

Если шаг слишком большой, модель может перескакивать минимум и обучение станет нестабильным. Если слишком маленький – обучение будет идти очень медленно или практически остановится.

Learning rate – один из самых чувствительных гиперпараметров модели. Его выбор часто важнее выбора самой модели или количества данных.

На практике используют:

* постоянный learning rate
* уменьшающийся learning rate
* адаптивные методы (например, Adam), которые подбирают шаг автоматически

С практической точки зрения learning rate определяет баланс между скоростью обучения и устойчивостью сходимости.

#### Log loss (логарифмическая функция потерь)

Log loss – это функция потерь для задач классификации, которая учитывает не только правильность предсказания, но и уверенность модели.

Если модель уверенно предсказывает правильный класс, log loss мал. Если она уверенно ошибается, log loss резко возрастает. Поэтому эта метрика "наказывает" за самоуверенные ошибки.

Log loss напрямую работает с вероятностями, а не с готовыми классами. Две модели могут иметь одинаковую accuracy, но разный log loss – потому что одна даёт более адекватные вероятности.

Log loss тесно связан с:

* логистической регрессией
* максимизацией правдоподобия (MLE)
* кросс-энтропией

В бинарной классификации минимизация log loss эквивалентна обучению модели, которая максимизирует вероятность наблюдаемых данных.

Интуитивно log loss отвечает на вопрос: "Насколько модель честна в своей уверенности"?

В практических главах это важно: если модель участвует в ранжировании, рекомендациях или принятии решений, качество вероятностей часто важнее простой точности.

#### Loss-функция (функция потерь)

Loss-функция измеряет, насколько плохо модель предсказывает результат на конкретном примере. Примеры:

* MSE для регрессии
* log loss (logarithmic loss) для классификации

Минимизация loss-функции – центральная задача обучения модели.

#### Лемматизация

Лемматизация – это приведение слов к их базовой, словарной форме (лемме).

Например:

"бежал", "бегу", "бегут" → "бежать"

"книги", "книгой", "книгах" → "книга"

В отличие от простого стемминга, лемматизация учитывает морфологию и часть речи, поэтому результат обычно более корректен с точки зрения языка.

В задачах машинного обучения лемматизация используется как этап предобработки текста перед Bag-of-Words, TF-IDF или обучением моделей. Она уменьшает размер словаря и помогает модели лучше обобщать смысл, а не формы слов.

#### Линейная регрессия

Линейная регрессия – это базовая модель для задач регрессии, которая предсказывает числовое значение на основе линейной комбинации признаков:

$$
\hat{y} = w \cdot x + b
$$

где $$w$$ – вектор весов, $$x$$ – вектор признаков, а $$b$$ – bias.

Модель подбирает веса так, чтобы минимизировать MSE (среднеквадратичную ошибку) или эквивалентно через MLE для гауссовских ошибок. Обучение обычно выполняется с помощью градиентного спуска или его вариаций (batch, mini-batch, SGD).

Линейная регрессия проста, интерпретируема и хорошо подходит для первых экспериментов с данными. Она показывает, как каждый признак влияет на итоговое предсказание, и служит отправной точкой для более сложных моделей.

Интуитивно линейная регрессия отвечает на вопрос: "Как меняется результат при изменении признаков, если все остальные фиксированы?"

С практической точки зрения линейная регрессия используется:

* для прогнозирования цен, спроса, температуры
* в финансовых и экономических моделях
* как базовая модель для проверки качества признаков и признакового пространства.

#### Логистическая регрессия

Логистическая регрессия – это модель для задач классификации, которая прогнозирует вероятность принадлежности объекта к определённому классу.

Идея состоит в том, чтобы сначала применить аффинное преобразование к признакам (взвесить их и добавить bias), а затем преобразовать результат с помощью логистической функции (sigmoid):

$$
\hat{y} = \sigma(w \cdot x + b) = \frac{1}{1 + e^{-(w \cdot x + b)}}
$$

На выходе получается число от 0 до 1, которое интерпретируется как вероятность. Для бинарной классификации чаще всего используют log loss (cross-entropy) как функцию ошибки, а параметры модели подбираются с помощью градиентного спуска или MLE.

Логистическая регрессия проста, интерпретируема и часто служит базовой моделью для проверки признаков и понимания данных. При этом она может быть расширена на многоклассовую классификацию через `softmax`.

Интуитивно логистическая регрессия отвечает на вопрос: "Насколько вероятно, что объект принадлежит к этому классу, если взвесить все признаки?"

С практической точки зрения она хорошо работает для текстовой классификации, медицины, кредитных скорингов и любых задач, где важна вероятность принадлежности, а не точное численное предсказание.

#### Логика энтропии

Логика энтропии – это способ рассуждения через меру неопределённости.

Энтропия показывает, насколько система "неопределённа" или "хаотична". Если все объекты принадлежат одному классу – энтропия минимальна. Если классы распределены равномерно – энтропия максимальна.

В машинном обучении логика энтропии означает:

* хороший признак уменьшает неопределённость
* хорошее разбиение делает данные более "чистыми"
* информация измеряется тем, насколько мы сократили хаос

Именно поэтому в деревьях решений используется information gain – он измеряет снижение энтропии после разбиения.

Интуитивно логика энтропии отвечает на вопрос: "Насколько стало понятнее после того, как мы задали этот вопрос?"

Важно понимать: энтропия – это не про "беспорядок" в бытовом смысле, а про степень неопределённости распределения.

В практическом ML логика энтропии связывает:

* вероятности
* information gain
* деревья решений
* probabilistic-мышление

По сути, это способ формализовать идею: "Информация – это уменьшение неопределённости".

#### Локальный регрессор

Локальный регрессор – это модель, которая делает предсказание, опираясь только на ближайшие точки к рассматриваемому объекту.

В отличие от глобальных моделей (например, линейной регрессии), которые строят одну формулу для всех данных, локальный регрессор подстраивается под конкретную область пространства признаков.

Идея простая:

* для нового объекта выбираются ближайшие точки
* на них строится локальная аппроксимация
* результат вычисляется на основе этого локального окружения

Примеры:

* k-NN в режиме регрессии
* LOESS / LOWESS
* локально-взвешенная линейная регрессия

Плюсы:

* хорошо ловит сложные нелинейные зависимости
* гибко адаптируется к данным

Минусы:

* плохо масштабируется на большие данные
* чувствителен к шуму
* требует выбора метрики расстояния

Интуитивно локальный регрессор отвечает на вопрос: "Как ведут себя данные рядом с этой точкой?"

С точки зрения компромисса между смещением и дисперсией (bias–variance) локальные модели обычно имеют низкое смещение (bias), но могут иметь высокую дисперсию (variance), особенно при малом количестве соседей.

#### MLE (Maximum Likelihood Estimation)

MLE – метод максимального правдоподобия, способ оценки параметров модели, при котором выбираются такие параметры, при которых наблюдаемые данные наиболее вероятны.

Идея MLE состоит в том, что мы не минимизируем ошибку напрямую, а максимизируем вероятность получить именно те данные, которые мы видим, при заданной модели.

Формально это выглядит как максимизация функции правдоподобия:

$$
\mathcal{L}(\theta) = p(y \mid x, \theta)
$$

На практике чаще работают с логарифмом правдоподобия, так как он удобнее для вычислений.

Важный и полезный факт: для линейной регрессии с гауссовским шумом максимизация правдоподобия эквивалентна минимизации MSE. Именно поэтому MSE возникает не как произвольная формула, а как следствие вероятностных предположений о данных.

MLE лежит в основе многих моделей:

* линейной и логистической регрессии
* обобщенных линейных моделей
* нейросетей (через log loss и cross-entropy)

Интуитивно MLE отвечает на вопрос: "При каких параметрах модели наблюдаемые данные выглядели бы наименее удивительными?"

С практической точки зрения MLE связывает машинное обучение с вероятностью и статистикой и позволяет осмысленно выбирать loss-функции, а не подбирать их наугад.

#### MSE (Mean Squared Error)

MSE – среднеквадратичная ошибка, одна из самых распространенных loss-функций для задач регрессии.

Она измеряет средний квадрат разницы между предсказанием модели и истинным значением:

$$
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

Возведение ошибки в квадрат усиливает влияние больших отклонений, поэтому MSE особенно чувствительна к выбросам.

С интуитивной точки зрения MSE отвечает на вопрос: "Насколько в среднем модель промахивается, если крупные ошибки считать особенно плохими?"

MSE хорошо сочетается с линейными моделями, потому что:

* она гладкая и дифференцируемая
* имеет простой градиент
* приводит к удобным аналитическим и численным решениям

В градиентном спуске производная MSE по параметрам модели прямо указывает направление, в котором нужно уменьшать ошибку.

На практике MSE часто используется не только как метрика качества, но и как функция, которую модель минимизирует в процессе обучения.

#### Манхэттенское расстояние

Манхэттенское расстояние (L1-расстояние) – это мера расстояния между двумя точками, равная сумме абсолютных разностей их координат:

$$
d(x, y) = \sum_i |x_i - y_i|
$$

Свое название оно получило из аналогии с перемещением по улицам Манхэттена, где нельзя идти по диагонали, а нужно двигаться вдоль сетки улиц.

В машинном обучении Манхэттенское расстояние используется:

* в алгоритмах ближайших соседей (k-NN)
* при работе с разреженными признаками
* в задачах кластеризации
* как альтернатива евклидову расстоянию

Манхэттенское расстояние менее чувствительно к отдельным большим отклонениям по одной координате, чем евклидово. Это делает его полезным при наличии выбросов или в высокоразмерных пространствах.

Интуитивно Манхэттенское расстояние отвечает на вопрос: "Сколько всего нужно пройти по осям, чтобы добраться из одной точки в другую?"

С практической точки зрения L1-расстояние хорошо сочетается с L1-регуляризацией и разреженными векторами, такими как Bag-of-Words.

#### Матричная факторизация

Матричная факторизация – это подход в рекомендательных системах, при котором большая разреженная матрица взаимодействий разбивается на несколько меньших матриц.

Обычно берут матрицу "пользователь – объект", где записано, кто что смотрел, покупал или оценивал. Эта матрица почти всегда разреженная: большинство значений неизвестны.

Идея в том, что каждый пользователь и каждый объект можно описать набором скрытых факторов. Факторизация как раз и находит эти скрытые представления.

В результате:

* пользователи и объекты превращаются в векторы
* рекомендация сводится к скалярному произведению этих векторов
* близость векторов означает высокую вероятность интереса

Матричная факторизация:

* лежит в основе коллаборативной фильтрации
* хорошо работает при большом количестве данных
* плохо справляется с cold start без дополнительных признаков

Интуитивно это выглядит так: "И пользователи, и объекты живут в одном скрытом пространстве интересов".

Этот термин хорошо связывается с эмбеддингами, косинусным сходством и геометрической интерпретацией рекомендаций.

#### Минковского Расстояние&#x20;

Расстояние Минковского – это обобщённая метрика расстояния между двумя векторами, которая включает в себя частные случаи других популярных расстояний.

Оно определяется формулой:

$$
d(x, y) = \left( \sum_i |x_i - y_i|^p \right)^{\frac{1}{p}}
$$

где параметр $$p \ge 1$$ задаёт тип расстояния.

Частные случаи:

* при $$p = 1$$ получается Манхэттенское расстояние (L1)
* при $$p = 2$$ – евклидово расстояние (L2)
* при $$p \to \infty$$ – расстояние Чебышёва

В машинном обучении расстояние Минковского используется в алгоритмах, основанных на близости объектов, прежде всего в k-NN и методах кластеризации.

Выбор параметра $$p$$ влияет на чувствительность расстояния к большим отклонениям по отдельным координатам и на геометрию пространства признаков.

Интуитивно расстояние Минковского – это способ выбрать, как именно измерять "близость" объектов: по сумме шагов, по прямой или по максимальному отклонению.

С практической точки зрения расстояние Минковского позволяет гибко настраивать метрику под структуру данных и задачу.

#### Модель

Модель – это математическая функция с параметрами, которая аппроксимирует зависимость между входными данными и результатом.

Примеры:

* линейная регрессия
* логистическая регрессия
* нейросеть

Модель не "знает" мир – она лишь приближает его на основе данных.

Добавляю, коротко и понятно.

#### N-граммы

N-грамма – это последовательность из _n_ подряд идущих элементов в тексте. Элементами обычно являются слова или символы.

Примеры для фразы: "машинное обучение работает"

* униграммы (n = 1): машинное, обучение, работает
* биграммы (n = 2): машинное обучение, обучение работает
* триграммы (n = 3): машинное обучение работает

В NLP n-граммы позволяют учитывать контекст, а не только отдельные слова. Например, биграмма "не плохо" передаёт другой смысл, чем слова "не" и "плохо" по отдельности.

n-граммы часто используются вместе с:

* bag-of-words
* TF-IDF
* классификацией текста
* языковыми моделями

Чем больше n, тем точнее контекст, но тем сильнее растёт размерность признакового пространства и разреженность данных. Поэтому на практике обычно ограничиваются униграммами и биграммами.

Интуитивно n-граммы – это компромисс между пониманием смысла и сложностью модели.

#### NLP (Natural Language Processing, обработка естественного языка)

NLP – это область машинного обучения, которая занимается работой с текстом и языком: словами, предложениями и смыслами.

Задача NLP – превратить человеческий язык в форму, с которой может работать модель. Для этого текст сначала очищают и упрощают, а потом превращают в числа.

Типичные задачи NLP:

* классификация текста (спам, тональность, тематика)
* поиск и сравнение текстов
* извлечение ключевых слов и сущностей
* ответы на вопросы и диалоги

На практике NLP почти всегда начинается с простых шагов: токенизация, лемматизация или стемминг, удаление стоп-слов. Затем текст кодируется с помощью bag-of-words, TF-IDF или эмбеддингов. После этого с текстом можно работать так же, как с любыми числовыми признаками.

Важно понимать, что для модели текст – это не "слова", а точки и векторы в пространстве. Смысл появляется не напрямую, а через расстояния, направления и статистику совместных появлений слов.

Интуитивно NLP – это попытка научить компьютер видеть в тексте структуру и закономерности, а не просто набор символов.

#### Нелинейный регрессор

Нелинейный регрессор – это модель регрессии, в которой зависимость между признаками и целевой переменной не описывается прямой линией.

В линейной регрессии предполагается, что изменение признаков влияет на результат линейно.

В нелинейной регрессии связь может быть более сложной: изгибающейся, экспоненциальной, логарифмической или произвольной формы.

Нелинейность может появляться:

* из-за самой модели (деревья решений, нейросети)
* из-за преобразования признаков (полиномиальные признаки, логарифмы и т.д.)

Примеры нелинейных регрессоров:

* полиномиальная регрессия
* деревья решений
* градиентный бустинг
* нейронные сети

Нелинейные модели способны описывать сложные зависимости, но:

* требуют больше данных
* более склонны к переобучению
* сложнее интерпретируются

Интуитивно нелинейный регрессор – это попытка подогнать не прямую линию, а гибкую кривую, которая лучше повторяет структуру данных.

С точки зрения компромисса между смещением и дисперсией (bias–variance tradeoff), нелинейные регрессоры, как правило, уменьшают смещение (bias), но могут увеличивать дисперсию (variance).

#### Нормализация

Нормализация – приведение признаков к сопоставимому масштабу. Например, значения в диапазон \[0, 1] или с нулевым средним и единичной дисперсией.

Без нормализации многие алгоритмы обучаются хуже или нестабильно.

#### One-hot encoding

One-hot encoding – это способ кодирования категориальных признаков в числовой вид с помощью бинарных векторов.

Каждой категории соответствует отдельная координата вектора. Для конкретного объекта ровно одна координата равна 1, а все остальные равны 0.

Например, признак "цвет" со значениями {красный, зеленый, синий} может быть закодирован так:

красный → \[1, 0, 0]

зеленый → \[0, 1, 0]

синий → \[0, 0, 1]

One-hot encoding широко используется в линейных моделях, логистической регрессии и нейросетях, когда категории не имеют естественного порядка.

Главный недостаток one-hot encoding – рост размерности признакового пространства при большом количестве категорий. В текстовых задачах Bag-of-Words и TF-IDF по сути являются частным случаем one-hot представления, взвешенного по частоте.

В более сложных моделях и при большом числе категорий one-hot encoding часто заменяют эмбеддингами, которые позволяют компактно представить категориальные данные и учитывать скрытые связи между ними.

#### ONNX (Open Neural Network Exchange)

ONNX – это открытый формат для обмена нейросетевыми моделями между разными фреймворками и средами выполнения.

Идея проста: модель можно обучить в одной системе (например, PyTorch или TensorFlow), а затем экспортировать её в ONNX и использовать в другой (например, в C++, .NET или мобильном приложении) без необходимости заново писать или обучать модель.

ONNX позволяет:

* переносить модели между фреймворками
* ускорять инференс на разных устройствах
* использовать оптимизированные runtime для CPU, GPU и edge

Интуитивно ONNX – это "универсальный паспорт" модели: она сохранена в нейтральном виде, который понимают разные системы.

С практической точки зрения ONNX облегчает интеграцию ML-моделей в продакшн, ускоряет запуск и упрощает поддержку разных платформ.

#### Ортогональные векторы

Ортогональные векторы – это векторы, которые перпендикулярны друг другу. Формально это означает, что их скалярное произведение равно нулю:

$$
A \cdot B = 0
$$

Геометрически ортогональность означает отсутствие проекции одного вектора на другой. Векторы не имеют общего направления и считаются полностью независимыми в смысле ориентации в пространстве.

В машинном обучении ортогональные векторы интерпретируются как несвязанные или несхожие признаки. Например, если cosine similarity равна нулю, соответствующие векторы ортогональны и не имеют смыслового пересечения.

Ортогональность играет важную роль в:

* линейной алгебре и базисах признаков
* снижении корреляции между признаками
* анализе эмбеддингов
* attention-механизмах, где ортогональные key-векторы не влияют на результат

Интуитивно ортогональные векторы отвечают ситуации, когда знание одного признака не дает информации о другом. Это понятие помогает понять, почему одни признаки усиливают друг друга, а другие не взаимодействуют вовсе.

#### Переобучение (Overfitting)

Переобучение возникает, когда модель слишком хорошо запоминает обучающие данные, но плохо обобщает на новые.

Обычно это следствие слишком сложной модели или недостатка данных.

#### Пространство признаков

Пространство признаков – это абстрактное пространство, в котором каждая ось соответствует одному признаку, а каждый объект – точка в этом пространстве.

Именно в этом пространстве мы считаем расстояния, углы и сходство.

#### Седловая точка

Седловая точка — это точка в пространстве параметров, в которой градиент функции равен нулю, но которая не является ни локальным минимумом, ни локальным максимумом.

В одних направлениях функция в седловой точке ведёт себя как минимум, а в других — как максимум. Геометрически такую точку можно представить в виде седла: вдоль одной оси поверхность «проваливается», а вдоль другой – "поднимается".

Для методов градиентного спуска седловые точки представляют особую проблему. Поскольку градиент в них равен нулю, алгоритм может временно "застрять" в такой точке, даже несмотря на то, что она не является точкой оптимума.

В высокоразмерных пространствах, характерных для задач машинного обучения, седловые точки встречаются значительно чаще, чем локальные минимумы. Именно поэтому процесс обучения иногда замедляется или выглядит нестабильным.

Стохастический градиентный спуск и его модификации помогают справляться с седловыми точками за счёт шума в оценке градиента. Этот шум позволяет алгоритму "выталкиваться" из плоских или квазистационарных областей.

Интуитивно седловую точку можно представить как ситуацию, в которой модель «не понимает», в каком направлении двигаться дальше: локально поверхность почти плоская, но глобально решение всё ещё далеко от оптимального.

#### Стемминг

Стемминг – это упрощенный способ приведения слов к общей основе (стему) путем механического отсечения окончаний и суффиксов.

Например:

"бегу”, "бежал", "бегущий" → "бег"

"connection", "connected", "connecting" → "connect"

В отличие от лемматизации, стемминг:

* не опирается на словари и грамматику
* работает быстрее
* может порождать формы, которые не являются реальными словами

Стемминг часто используется как быстрый этап предобработки текста перед Bag-of-Words или TF-IDF, особенно в задачах, где точная языковая форма менее важна, чем общая тема документа.

Недостаток стемминга в том, что он может объединять слова с разным смыслом или, наоборот, не объединять близкие по значению формы. Поэтому в более точных системах, особенно для сложных языков, чаще предпочитают лемматизацию.

В практическом смысле выбор между стеммингом и лемматизацией – это компромисс между скоростью, простотой и качеством смыслового представления текста.

#### Стоп-слова

Стоп-слова – это часто встречающиеся слова, которые обычно несут мало смысловой нагрузки: "и", "в", "на", "это", "the", "is" и т.д.

При анализе текста такие слова часто удаляют, чтобы:

* уменьшить размерность признаков
* снизить шум
* сосредоточиться на содержательных словах

Стоп-слова особенно актуальны при использовании Bag-of-Words и TF-IDF. Однако при работе с современными эмбеддингами и нейросетями их удаление не всегда необходимо и иногда даже вредно, поскольку модель может использовать контекст, в том числе служебные слова.

#### Стохастический градиентный спуск (SGD)

Стохастический градиентный спуск – это вариант градиентного спуска, при котором параметры модели обновляются не по всей обучающей выборке сразу, а по одному примеру или по небольшому случайному подмножеству данных.

В классическом градиентном спуске градиент вычисляется по всем данным, что дает точное направление, но требует больших вычислений. В SGD градиент является приближенным, но обновления происходят гораздо чаще.

Интуитивно SGD можно представить как движение к минимуму с шумом: каждый шаг может быть неточным, но в среднем модель движется в правильном направлении.

Стохастический градиентный спуск:

* быстрее на больших данных
* позволяет обучаться онлайн, по мере поступления данных
* помогает выходить из неглубоких локальных минимумов

Недостатком SGD является более шумная траектория обучения и чувствительность к learning rate.

На практике чаще используют mini-batch SGD, при котором градиент считается по небольшим батчам данных. Этот подход сочетает устойчивость классического градиентного спуска и эффективность стохастического.

#### Saturation-поведение

Saturation-поведение – это ситуация, при которой выход модели или нейрона перестает чувствительно реагировать на изменение входных данных.

Чаще всего saturation возникает:

* в сигмоидных и tanh-активациях при больших по модулю входах
* при слишком больших весах
* при неудачном learning rate

В состоянии saturation градиенты становятся очень маленькими, обучение замедляется или практически останавливается. Это явление известно как vanishing gradients.

Интуитивно saturation-поведение можно представить как "потолок": сколько бы мы ни увеличивали вход, результат почти не меняется.

С практической точки зрения понимание saturation важно при выборе активаций, инициализации весов и архитектуры модели.

#### TF-IDF

TF-IDF (Term Frequency – Inverse Document Frequency) – улучшенная версия Bag-of-Words, которая учитывает не только частоту слова в документе, но и его редкость во всей коллекции.

Редкие, но информативные слова получают больший вес, чем частые служебные.

TF-IDF часто используется как базовое представление текста перед классификацией или поиском.

#### Train / Test split

Train/Test split – разделение данных на обучающую и тестовую выборки. Модель обучается на одной части данных и проверяется на другой.

Это позволяет оценить, насколько хорошо модель обобщает знания.
