---
description: Обзор экосистемы PHP для машинного обучения и научных вычислений.
---

# Экосистема ML в PHP

Когда говорят, что "в PHP нет машинного обучения", обычно путают две разные вещи.

В PHP действительно редко обучают большие нейросети с нуля (во всяком случае на данный момент), но PHP давно и уверенно живет в мире применения моделей, работы с векторами, статистикой, классификацией, эмбеддингами и численной математикой.

Экосистема здесь не шумная, но зрелая. Она состоит из четырёх слоев:

* библиотеки классического ML
* математический фундамент
* инструменты интеграции с современными ML-системами
* интеграция с внешними ML-сервисами

Разберем их последовательно.

### Классическое машинное обучение на PHP

Начнем с библиотек, которые реализуют сами алгоритмы машинного обучения прямо на PHP, без вызовов внешних сервисов.

#### **PHP-ML**&#x20;

Репозиторий: [https://github.com/jorgecasas/php-ml](https://github.com/jorgecasas/php-ml)

Статус: <mark style="color:$warning;">давно не обновлялась</mark>

PHP-ML – это отправная точка для понимания ML в PHP. Здесь есть все основные алгоритмы из классического курса: k-NN, линейная и логистическая регрессия, наивный Байес, SVM, деревья решений, k-means.&#x20;

Важно понимать философию PHP-ML. Она не пытается конкурировать с PyTorch или scikit-learn по производительности. Ее цель – дать программисту понятный и честный ML-инструмент прямо внутри PHP-кода. Её код легко читать, легко отлаживать, легко объяснять. Для книги и обучения это почти идеальный вариант.

Типичный сценарий: у вас есть признаки из базы данных, вы хотите быстро обучить модель для классификации или регрессии, сохранить ее и использовать в runtime без внешних сервисов.

Рассмотрим простой и показательный пример. В нём мы обучаем классификатор $$k$$-ближайших соседей ([k-NN](../glossarii.md#k-nn-k-nearest-neighbors-k-blizhaishikh-sosedei)) на небольшом наборе точек, каждая из которых принадлежит одному из двух классов – $$a$$ или $$b$$. После обучения модель должна определить, к какому классу относится новая точка.

Мы задаём обучающую выборку в виде координат на плоскости и соответствующие им метки классов:

```php
use Phpml\Classification\KNearestNeighbors;

$samples = [[1, 3], [1, 4], [2, 4], [3, 1], [4, 1], [4, 2]];
$labels = ['a', 'a', 'a', 'b', 'b', 'b'];

$classifier = new KNearestNeighbors();
$classifier->train($samples, $labels);

$prediction = $classifier->predict([3, 2]);

echo $prediction;
// Результат: 'b'
```

{% hint style="info" %}
Чтобы самостоятельно протестировать этот код, установите примеры из официального репозитория [GitHub](https://github.com/apphp/ai-for-php-developers-examples) или воспользуйтесь [онлайн-демонстрацией](https://aiwithphp.org/books/ai-for-php-developers/examples/ml-ecosystem-in-php) для его запуска.
{% endhint %}

Для точки $$[3, 2]$$ алгоритм возвращает класс "$$b$$", потому что её ближайшие соседи в обучающей выборке относятся именно к этому классу. Никакой "магии" здесь нет: k-NN просто смотрит, какие точки находятся ближе всего, и "голосует" по их меткам.

Именно эта наглядность и является большим плюсом алгоритма. Код легко читается, модель просто отлаживать, а математический смысл происходящего можно объяснить буквально на пальцах – через расстояния между точками и ближайшее окружение.

Но если PHP-ML – это "учебник", то следующая библиотека – уже "инженерный инструмент".

#### **Rubix ML**

Сайт и репозиторий: [https://github.com/RubixML](https://github.com/RubixML)

Статус: <mark style="color:green;">**активный**</mark>

Rubix ML – это полноценный ML-фреймворк для PHP. Он ориентирован не на демонстрацию алгоритмов, а на построение воспроизводимых ML-пайплайнов: с трансформациями данных, сериализацией моделей, строгими интерфейсами и продакшен-подходом.

Rubix поддерживает классификацию, регрессию, кластеризацию и работу с датасетами как с first-class объектами.

Посмотрим, как это выглядит на практике.

Допустим, у нас есть данные для бинарной классификации. Код ниже также обучает классификатор $$k$$-ближайших соседей (k-NN), но уже на данных роста и веса с метками пола, а затем предсказывает метку для нового человека. Для параметров $$[172, 68]$$ модель возвращает "$$M$$", так как среди 3 ближайших соседей большинство с этой меткой.

```php
use Rubix\ML\Datasets\Labeled;
use Rubix\ML\Datasets\Unlabeled;
use Rubix\ML\Classifiers\KNearestNeighbors;

$samples = [
    [170, 65],
    [160, 50],
    [180, 80],
    [175, 70],
];

$labels = ['M', 'F', 'M', 'M'];

$dataset = new Labeled($samples, $labels);

$model = new KNearestNeighbors(3);
$model->train($dataset);

$testSamples = new Unlabeled([[172, 68]]);
$prediction = $model->predict($testSamples);

echo $prediction[0];
// Результат: 'M'
```

{% hint style="info" %}
Чтобы самостоятельно протестировать этот код, установите примеры из официального репозитория [GitHub](https://github.com/apphp/ai-for-php-developers-examples) или воспользуйтесь [онлайн-демонстрацией](https://aiwithphp.org/books/ai-for-php-developers/examples/ml-ecosystem-in-php) для его запуска.
{% endhint %}

Обратите внимание на важный момент.

Мы не передаем "сырые массивы" в модель – мы работаем с объектом `Unlabeled` который является подтипом  `Dataset`. Это принципиально другой уровень абстракции, который сразу приучает думать как ML-инженер, а не как автор скрипта для своего pet-проекта.

Rubix умеет сохранять модели, применять трансформеры, масштабировать признаки и работать с пайплайнами. В реальных PHP-системах это часто оказывает решающим, поэтому Rubix часто выбирают, когда модель – это не эксперимент, а часть долгоживущего сервиса, где важны версионирование, повторяемость и стабильность.

### Линейная алгебра и тензоры как основа ML

Любой ML-код, даже самый прикладной, в итоге сводится к операциям над векторами и матрицами. В PHP для этого существует несколько сильных решений.

#### **RubixML/Tensor**

Репозиторий: [https://github.com/RubixML/Tensor](https://github.com/RubixML/Tensor)

<div align="left"><figure><img src="https://img.shields.io/github/stars/RubixML/Tensor?style=social" alt=""><figcaption></figcaption></figure></div>

Статус: <mark style="color:green;">**активный**</mark>

RubixML/Tensor – это низкоуровневая библиотека линейной алгебры, оптимизированная именно под задачи машинного обучения. Здесь есть тензоры, матрицы, элементные (поэлементные) операции, преобразования и разложения.

Если Rubix ML – это "мозг", то Tensor – это "мышцы".

Эта библиотека особенно важна, если вы хотите писать ML-код, который не просто работает, а делает это стабильно и предсказуемо – с контролируемым потреблением памяти и производительностью.

#### **MathPHP**

Репозиторий: [https://github.com/markrogoyski/math-php](https://github.com/markrogoyski/math-php)&#x20;

<div align="left"><figure><img src="https://img.shields.io/github/stars/markrogoyski/math-php?style=social" alt=""><figcaption></figcaption></figure></div>

Статус: <mark style="color:green;">**активный**</mark>

MathPHP – универсальная математическая библиотека на чистом PHP. Линейная алгебра, статистика, вероятности, распределения, численные методы и прочее.

В контексте машинного обучения MathPHP часто используется не напрямую для моделей, а как фундамент для расчетов: расстояния, нормализация, статистические оценки, проверка гипотез.

Это библиотека, которая идеально подходит для объяснения математики "просто", без лишней  сложности и скрытых оптимизаций.

#### **NumPower**

Репозиторий: [https://github.com/RubixML/numpower](https://github.com/RubixML/numpower)

Статус: <mark style="color:green;">**активный**</mark>

NumPower – особый случай. Это PHP-расширение для высокопроизводительных численных вычислений, вдохновленное NumPy. Оно использует AVX2-инструкции на x86-64 и поддерживает CUDA для вычислений на GPU.

Фактически, это ответ на вопрос: "А можно ли делать в PHP настоящие численные вычисления на уровне scientific computing"?

И ответ – да, если вы готовы работать с расширениями и специфичной инфраструктурой.

NumPower актуален там, где PHP используется не как веб-слой, а как вычислительный движок.

#### **NumPHP и SciPhp**

NumPHP: [https://numphp.org](https://numphp.org/)

Статус: <mark style="color:$warning;">давно не обновлялась</mark>

SciPhp: [https://sciphp.org](https://sciphp.org/)

Статус: <mark style="color:$warning;">давно не обновлялась</mark>

Это библиотеки, вдохновленные NumPy и научным Python, но давно не обновлявшиеся. Сегодня они скорее представляют исторический интерес, чем основу для новых проектов.

Тем не менее, они важны для понимания того, что идеи научных вычислений в PHP появились задолго до LLM и хайпа вокруг AI.

### Современные ML-интеграции: токены, эмбеддинги, пайплайны данных

Современное машинное обучение редко ограничивается "алгоритмом". Вокруг него всегда есть инфраструктура: токенизация, подготовка данных, потоковая обработка.

#### **Tiktoken PHP**

Репозиторий: [https://github.com/yethee/tiktoken-php](https://github.com/yethee/tiktoken-php)

Статус: <mark style="color:green;">**активный**</mark>

tiktoken-php – это PHP-порт токенизатора OpenAI. Он используется для подсчета токенов, разбиения текста и подготовки данных для LLM.

Если вы работаете с GPT, Claude или Gemini из PHP, эта библиотека становится практически обязательной. Она позволяет понимать реальную стоимость запросов, длину контекста и поведение модели еще до вызова API.

#### **TransformersPHP**

Репозиторий: [https://github.com/CodeWithKyrian/transformers-php](https://github.com/CodeWithKyrian/transformers-php)\
Статус: <mark style="color:green;">**активный**</mark>

Transformers PHP – один из самых интересных и показательных проектов в современной PHP ML-экосистеме. Это библиотека, которая позволяет использовать трансформер-модели (BERT, RoBERTa, DistilBERT и др.) напрямую из PHP, без Python и без внешних API.

По сути, это PHP-ориентированная обертка над идеями Hugging Face Transformers, адаптированная под PHP-экосистему и реальные прикладные сценарии.

Ключевая особенность библиотеки – локальный [инференс](../glossarii.md#inferens-inference). Модели загружаются и выполняются на стороне PHP-приложения (через ONNX Runtime), что открывает важные архитектурные возможности:

* отсутствие сетевых вызовов к LLM API
* полный контроль над данными (важно для privacy)
* предсказуемая задержка
* возможность оффлайн-работы

Transformers PHP поддерживает типовые задачи NLP:

* получение эмбеддингов
* классификацию текста
* семантическое сравнение
* feature extraction для downstream-задач

Пример использования выглядит концептуально просто: вы загружаете предобученную модель и применяете ее к тексту так же, как это делали бы в Python – но уже внутри PHP-кода. TransformersPHP предлагает простой pipeline API для задач вроде анализа настроений, классификации текста, семантического сравнения и т.д. В примере ниже модель определяет тональность двух фраз и показывает метку и score.

```php
use function Codewithkyrian\Transformers\Pipelines\pipeline;

// Выделить конвейер для анализа настроений
$classifier = pipeline('sentiment-analysis');

$out = $classifier(['I love transformers!']);
echo print_r($out, true);
// Array ( 
//   [label] => POSITIVE 
//   [score] => 0.99978870153427 
// )

$out = $classifier(['I hate transformers!']);
echo print_r($out, true);
// Array ( 
//   [label] => NEGATIVE 
//   [score] => 0.99863630533218 
// )
```

{% hint style="info" %}
Чтобы самостоятельно протестировать этот код, установите примеры из официального репозитория [GitHub](https://github.com/apphp/ai-for-php-developers-examples) или воспользуйтесь [онлайн-демонстрацией](https://aiwithphp.org/books/ai-for-php-developers/examples/ml-ecosystem-in-php) для его запуска.
{% endhint %}

Важно понимать архитектурную роль Transformers PHP.

Эта библиотека не конкурирует с большими LLM-сервисами вроде GPT или Claude. Она закрывает другой, очень важный слой:

* быстрые эмбеддинги
* локальная классификация
* семантический поиск
* lightweight NLP без внешних зависимостей

В связке с PHP это выглядит особенно логично. PHP остается центральным слоем бизнес-логики, а трансформеры становятся встроенным инструментом, а не удаленным сервисом.

Transformers PHP –  это хороший пример того, как современный ML постепенно перестает быть "чужим" для PHP и становится частью его нативной экосистемы, пусть и через аккуратные инженерные мосты вроде ONNX.

#### Rindow Math Matrix

Репозиторий: [https://github.com/rindow/rindow-math-matrix](https://github.com/rindow/rindow-math-matrix)

Статус: <mark style="color:green;">**активный**</mark>

Rindow Math Matrix – это библиотека линейной алгебры и матричных вычислений, ориентированная на ML и численные методы. Она часто используется в связке с другими компонентами экосистемы Rindow.

Хороший выбор, если вам нужен строгий математический API и контроль над численными операциями.

#### **Flow PHP**

Репозиторий: [https://github.com/flow-php/flow](https://github.com/flow-php/flow)

Статус: <mark style="color:green;">**активный**</mark>

Flow PHP – это не ML-библиотека в чистом виде, а фреймворк для обработки данных. ETL, пайплайны, трансформации, валидация, потоки данных.

В реальных ML-системах именно этот слой часто оказывается самым сложным. Данные нужно собрать, очистить, нормализовать и только потом подать в модель.

Flow PHP закрывает этот разрыв между "данные где-то лежат" и "модель уже работает".

### Интеграция с внешними ML-сервисами

На практике, в большинстве production-сценариев, использование ML в PHP – это не обучение моделей, а инференс через API.

#### **LLPhant**

Репозиторий: [https://github.com/LLPhant/LLPhant](https://github.com/LLPhant/LLPhant?utm_source=chatgpt.com)\
Статус: <mark style="color:green;">**активный**</mark>

LLPhant – это современный Generative AI-фреймворк для PHP, который решает уже не задачу "реализовать алгоритм", а задачу "построить AI-приложение".

Если PHP-ML и Rubix работают на уровне моделей и математики, а TransformersPHP – на уровне локального инференса, то LLPhant закрывает уровень архитектуры вокруг LLM.

Он вдохновлен LangChain и LlamaIndex, но адаптирован под PHP-экосистему.

LLPhant предоставляет:

* единый интерфейс к различным LLM (OpenAI, Anthropic, Mistral, Ollama и др.)
* работу с embeddings
* поддержку vector stores (Redis, Doctrine, Qdrant, in-memory и др.)
* построение RAG-сценариев (retrieval + generation)
* чат-память и управление диалогами
* инструменты для агентов и tool calling

Архитектурно LLPhant важен тем, что он позволяет рассматривать LLM не как "HTTP-вызов", а как компонент системы. Вы работаете не просто с API, а с абстракциями:

* Chat
* Embeddings
* VectorStore
* Document
* Memory
* Pipeline

Это переводит использование LLM из разряда "скрипт с запросом к OpenAI" в разряд воспроизводимой архитектуры.

Простейший пример:

```php
use LLPhant\Chat\OpenAIChat;
use LLPhant\Chat\Message;
use LLPhant\Chat\Enums\ChatRole;

$chat = new OpenAIChat();

$message = new Message();
$message->role = ChatRole::User;
$message->content = 'What is the capital of France?';

$response = $chat->generateText($message);
echo $response;

// Результат: 
// The capital of France is Paris.
```

{% hint style="info" %}
Чтобы самостоятельно протестировать этот код, установите примеры из официального репозитория [GitHub](https://github.com/apphp/ai-for-php-developers-examples) или воспользуйтесь [онлайн-демонстрацией](https://aiwithphp.org/books/ai-for-php-developers/examples/ml-ecosystem-in-php) для его запуска.
{% endhint %}

Но реальная сила LLPhant раскрывается в RAG-сценариях:

1. Вы создаете embeddings для документов.
2. Сохраняете их в vector store.
3. При запросе пользователя находите релевантный контекст.
4. Передаете его в модель.
5. Получаете ответ, основанный на ваших данных.

Именно поэтому LLPhant занимает особое место в экосистеме PHP ML. Это не библиотека линейной алгебры и не инструмент классического машинного обучения, и не просто обёртка для локального инференса. Это фреймворк, который позволяет строить полноценные AI-системы поверх LLM — с управлением контекстом, хранением данных и архитектурной структурой.

Если говорить образно:

* PHP-ML — это учебник,
* Rubix — инженерный инструмент,
* TransformersPHP — локальный инференс,
* LLPhant — инфраструктура для LLM-приложений.

Именно такие проекты показывают, что современная ML-экосистема в PHP – это уже не просто "подключить API", а полноценный архитектурный слой вокруг моделей.

#### **OpenAI, Anthropic, Gemini и другие LLM**

Под крупные LLM существуют PHP SDK или качественные HTTP-обертки. Через них PHP получает:

* эмбеддинги для текста,
* классификацию,
* генерацию,
* суммаризацию,
* извлечение структурированных данных.

С точки зрения архитектуры это выглядит так: модель живет вне PHP, а PHP становится "мозгом бизнес-логики", который знает, когда и зачем вызвать ML.

Именно здесь PHP особенно силен: он отлично интегрируется с очередями, базами, кэшем, платежами и UI.

#### **ONNX Runtime и инференс моделей**

Отдельного упоминания заслуживает [ONNX](../glossarii.md#one-hot-encoding). Через расширения или внешние сервисы PHP может выполнять инференс моделей, обученных в Python и экспортированных в ONNX-формат.

Это редкий, но важный кейс: модель обучается где угодно, а используется в PHP-приложении без Python в продакшене (через ONNX Runtime, расширения или внешний inference-сервис).

#### Компьютерное зрение и обработка сигналов

В задачах компьютерного зрения и обработки сигналов PHP не является лидирующим языком, однако базовые инструменты для интеграции таких решений всё же существуют. OpenCV может использоваться через биндинги, CLI-вызовы или внешние сервисы, при этом PHP выступает в роли управляющего и координирующего слоя.

В подобных сценариях PHP редко занимается численными вычислениями напрямую. Его роль – оркестрация: запуск и контроль CV-пайплайнов, передача данных между компонентами, интеграция с очередями, хранилищами и бизнес-логикой приложения. Это типичный пример того, как PHP эффективно работает с ML-компонентами, оставаясь центральной точкой управления, а не вычислительным ядром.

### Как читать эту экосистему целиком

Важно сделать один вывод, прежде чем двигаться дальше.

PHP – это не язык для соревнований по распознаванию изображений. Это язык, который соединяет машинное обучение с реальным продуктом. Его библиотеки заточены не под рекорды точности, а под: ясность кода, интеграцию, контроль данных и предсказуемость поведения.

Если вы понимаете, как работает модель математически, PHP даст вам достаточно инструментов, чтобы использовать ее в бою.

В этом смысле экосистема PHP и ML не является бедной – она прагматична и сфокусирована на прикладных задачах. PHP и машинное обучение – это про архитектурную роль PHP как слоя интеграции, оркестрации и бизнес-логики вокруг моделей:

* в применении моделей,
* в работе с эмбеддингами и векторами,
* в классификации и ранжировании,
* в оркестрации ML-сервисов,
* в соединении математики и бизнес-логики.

Именно поэтому экосистема PHP выглядит не как один монолит, а как набор точных инструментов.

{% hint style="info" %}
Для более широкого обзора экосистемы и актуальных экспериментов можно также обратиться к курируемой подборке Awesome PHP ML, где собраны библиотеки, инструменты и проекты, связанные с машинным обучением в PHP:

[Awesome PHP ML](https://github.com/apphp/awesome-php-ml)
{% endhint %}
