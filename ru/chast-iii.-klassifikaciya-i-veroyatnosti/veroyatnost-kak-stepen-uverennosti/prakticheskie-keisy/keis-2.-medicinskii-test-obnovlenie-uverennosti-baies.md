# Кейс 2. Медицинский тест: обновление уверенности (Байес)

#### Цель кейса

Этот кейс демонстрирует фундаментальную идею вероятности как степени уверенности: вероятность не является фиксированным свойством события – она обновляется при поступлении новой информации.

Мы разберем классический пример с медицинским тестом и увидим, почему высокая точность теста не означает высокой уверенности в диагнозе. Главная цель – научиться мыслить в терминах априорной и апостериорной вероятности.

#### Сценарий

Предположим, существует редкое заболевание.

Известно следующее:

* Болезнь встречается у 1 человека из 1000.
* Чувствительность теста (вероятность положительного результата при наличии болезни) – 99%.
* Специфичность теста (вероятность отрицательного результата у здорового человека) – 95%.

Пациент сдает тест и получает положительный результат.

<br>

Вопрос: какова вероятность того, что он действительно болен?

<br>

Интуитивный ответ часто звучит так: «примерно 99%». Но это неверно.

<br>

Причина – в редкости события.

***

#### Математическая постановка

<br>

Обозначим:

<br>

P(D) – вероятность болезни (априорная вероятность);

P(T+ | D) – вероятность положительного теста при болезни (чувствительность);

P(T+ | ¬D) – вероятность положительного теста при отсутствии болезни.

<br>

Нас интересует:

<br>

P(D | T+)

<br>

То есть вероятность болезни при условии положительного результата теста.

<br>

По формуле Байеса:

<br>

P(D | T+) = (P(T+ | D) · P(D)) / P(T+)

<br>

Где

<br>

P(T+) = P(T+ | D)·P(D) + P(T+ | ¬D)·P(¬D)

***

#### Реализация на PHP

```
$prior = 0.001;        // P(болезнь)
$sensitivity = 0.99;   // P(положительный | болезнь)
$specificity = 0.95;   // P(отрицательный | здоров)

$falsePositive = 1 - $specificity;  // P(положительный | здоров)

$posterior = ($sensitivity * $prior)
    / (($sensitivity * $prior) + ($falsePositive * (1 - $prior)));

echo round($posterior, 4);
```

Результат будет примерно:

<br>

0.0194

<br>

То есть около 1.94%.

***

#### Интерпретация результата

<br>

Несмотря на то, что тест «точный» (99% чувствительность), итоговая вероятность болезни после положительного результата составляет менее 2%.

<br>

Почему?

<br>

Потому что болезнь крайне редкая. Ложноположительные результаты, возникающие у большого числа здоровых людей, статистически «перекрывают» истинно положительные случаи.

<br>

Другими словами:

<br>

– априорная вероятность была очень низкой;

– один тест не смог радикально изменить уровень уверенности.

<br>

Это и есть обновление уверенности – переход от P(D) к P(D | T+).

***

#### Инженерный смысл

<br>

Этот пример важен не только для медицины. Он напрямую переносится на задачи машинного обучения:

<br>

– редкий фрод в платежах;

– редкие инциденты безопасности;

– редкие события в логах;

– поиск аномалий.

<br>

Даже очень «точная» модель может давать много ложных срабатываний, если событие само по себе встречается редко.

<br>

Поэтому при оценке моделей важно учитывать:

<br>

– базовую распространенность события;

– баланс классов;

– реальные последствия ложных срабатываний.

***

#### Типичная когнитивная ошибка

<br>

Люди склонны игнорировать априорную вероятность и концентрироваться только на точности теста. Это называется игнорированием базовой частоты (base rate neglect).

<br>

В ML эта ошибка проявляется так:

<br>

– модель с 99% accuracy кажется «отличной»;

– но если положительный класс составляет 0.5% выборки, такая точность может быть иллюзией.

***

#### Выводы

1. Вероятность – это не статичное свойство, а обновляемая степень уверенности.
2. Априорная вероятность играет решающую роль при интерпретации результата.
3. Даже очень точный тест не дает высокой уверенности, если событие редкое.
4. Байесовское обновление – это универсальный механизм пересчета уверенности при появлении новых данных.

<br>

Этот кейс формирует фундаментальное понимание: модель или тест дают нам новый сигнал, но окончательная уверенность всегда зависит от контекста, в котором этот сигнал получен.
