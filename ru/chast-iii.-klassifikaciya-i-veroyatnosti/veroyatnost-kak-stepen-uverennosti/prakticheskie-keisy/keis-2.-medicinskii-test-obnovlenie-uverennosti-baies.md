# Кейс 2. Медицинский тест: обновление уверенности (Байес)

#### Цель кейса

Этот кейс демонстрирует фундаментальную идею вероятности как степени уверенности: вероятность не является фиксированным свойством события – она обновляется при поступлении новой информации.

Мы разберем классический пример с медицинским тестом и увидим, почему высокая точность теста не означает высокой уверенности в диагнозе. Главная цель – научиться мыслить в терминах [априорной](../../../vvedenie/glossarii.md#apriornaya-i-aposteriornaya-veroyatnost) и [апостериорной](../../../vvedenie/glossarii.md#apriornaya-i-aposteriornaya-veroyatnost) вероятности.

#### Сценарий

Предположим, существует редкое заболевание.

Известно следующее:

* Болезнь встречается у 1 человека из 1000.
* Чувствительность теста (вероятность положительного результата при наличии болезни) – 99%.
* Специфичность теста (вероятность отрицательного результата у здорового человека) – 95%.

Пациент сдает тест и получает положительный результат.

**Вопрос**: какова вероятность того, что он действительно болен?

Интуитивный ответ часто звучит так: "примерно 99%". Но это неверно.

Причина – в редкости события.

#### Математическая постановка

Обозначим:

* $$P(D)$$ – вероятность болезни (априорная вероятность);
* $$P(T+ \mid D)$$ – вероятность положительного теста при болезни (чувствительность);
* $$P(T+ \mid \neg D)$$ – вероятность положительного теста при отсутствии болезни.

Нас интересует: $$P(D \mid T+)$$ - то есть вероятность болезни при условии положительного результата теста.

По формуле Байеса:

$$
P(D \mid T^+) = \frac{P(T^+ \mid D)\, P(D)}{P(T^+)}
$$

Где

$$
P(T^+) = P(T^+ \mid D)\,P(D) + P(T^+ \mid \neg D)\,P(\neg D)
$$



#### Реализация на PHP

```php
$prior = 0.001;        // P(болезнь)
$sensitivity = 0.99;   // P(положительный | болезнь)
$specificity = 0.95;   // P(отрицательный | здоров)

$falsePositive = 1 - $specificity;  // P(положительный | здоров)

$posterior = ($sensitivity * $prior) 
    / (($sensitivity * $prior) + ($falsePositive * (1 - $prior)));

echo "Истинно положительные случаи: " . ($sensitivity * $prior) . PHP_EOL;
echo "Ложноположительные результаты: " . ($falsePositive * (1 - $prior)) . PHP_EOL;
echo "Вероятность: " . round($posterior, 4);
```

Результат будет следующий:&#x20;

```
Истинно положительные случаи: 0.00099
Ложноположительные результаты: 0.04995
Вероятность: 0.0194
```

То есть около 1.94%.

#### Интерпретация результата

Несмотря на то, что тест "точный" (99% чувствительность), итоговая вероятность болезни после положительного результата составляет менее 2%.

Почему?

Потому что болезнь крайне редкая. Ложноположительные результаты, возникающие у большого числа здоровых людей, статистически "перекрывают" истинно положительные случаи.

Другими словами:

* априорная вероятность была очень низкой
* один тест не смог радикально изменить уровень уверенности

Это и есть обновление уверенности – переход от $$P(D)$$ к $$P(D \mid T+)$$.

#### Инженерный смысл

Этот пример важен не только для медицины. Он напрямую переносится на задачи машинного обучения:

* редкий фрод (_fraud –_ мошенничество) в платежах
* редкие инциденты безопасности
* редкие события в логах
* поиск аномалий

Даже очень "точная" модель может давать много ложных срабатываний, если событие само по себе встречается редко.

Поэтому при оценке моделей важно учитывать:

* базовую распространенность события
* баланс классов
* реальные последствия ложных срабатываний.

#### Типичная когнитивная ошибка

Люди склонны игнорировать априорную вероятность и концентрироваться только на точности теста. Это называется игнорированием базовой частоты ([base rate neglect](../../../vvedenie/glossarii.md#base-rate-neglect-ignorirovanie-bazovoi-chastoty)).

В ML эта ошибка проявляется так:

* модель с 99% accuracy кажется "отличной"
* но если положительный класс составляет 0.5% выборки, такая точность может быть иллюзией.

#### Выводы

1. Вероятность – это не статичное свойство, а обновляемая степень уверенности.
2. Априорная вероятность играет решающую роль при интерпретации результата.
3. Даже очень точный тест не дает высокой уверенности, если событие редкое.
4. [Байесовское обновление](../../../vvedenie/glossarii.md#bayesian-updating-baiesovskoe-obnovlenie) – это универсальный механизм пересчета уверенности при появлении новых данных.

Этот кейс формирует фундаментальное понимание: модель или тест дают нам новый сигнал, но окончательная уверенность всегда зависит от контекста, в котором этот сигнал получен.
