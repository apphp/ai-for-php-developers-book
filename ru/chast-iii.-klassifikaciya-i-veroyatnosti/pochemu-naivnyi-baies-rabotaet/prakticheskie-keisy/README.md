# Практические кейсы

Теория наивного Байеса выглядит слишком простой. Формула, несколько предположений, логарифмы – и модель готова. На этом месте часто возникает ощущение, что мы что-то упустили. Слишком уж легко для задачи, которая в реальности решает спам-фильтрацию, классификацию текста, определение намерений пользователя.

Именно поэтому дальше идут практические кейсы.

Их цель – не показать "как правильно писать ML-код", и не заменить полноценную библиотеку. Эти разборы нужны для другого: чтобы увидеть, как формулы из предыдущей главы буквально превращаются в несколько десятков строк обычного PHP-кода. Без магии, без скрытых оптимизаций, без нейросетей.

Во всех кейсах сначала используется чистый PHP. Это принципиально. Наивный Байес – редкий пример модели, которую можно реализовать почти напрямую из определения. Подсчет частот, логарифмы, суммирование – ровно то, о чем мы говорили в теории. Такой код легко читать, легко отлаживать и, что важнее, легко мысленно сопоставлять с формулами.

После этого тот же самый сценарий показывается с использованием RubixML. Здесь уже не видно внутренней кухни, но становится понятно, как эта же идея применяется в реальных проектах, где оптимизации уже спрятаны за интерфейсом библиотеки. Это не альтернатива чистому PHP, а следующий уровень абстракции.

Кейсы выстроены от простого к более реалистичному. Сначала – минимальная классификация на категориальных признаках, где особенно хорошо видно предположение о независимости. Затем – классический спам-фильтр, в котором каждый признак вносит свой вклад ("голос") в итоговую вероятность класса. И наконец – числовые признаки и [гауссово распределение](../../../vvedenie/zaklyuchitelnye-materialy/glossarii.md#gaussovo-raspredelenie), чтобы показать, что наивный Байес не ограничивается только текстами.

Если после этих разборов наивный Байес перестанет казаться странной и "слишком простой" моделью – значит, они сделали свою работу.

Итого, мы рассмотрим 3 кейса, где:

* Кейс 1. Категориальные признаки и частоты - понять механику
* Кейс 2. Спам-фильтр на словах (Bernoulli Naive Bayes) - связать с реальным ML
* Кейс 3. Числовые признаки (Gaussian Naive Bayes) - увидеть, что Байес не только про текст

Готовы? Тогда вперёд!
