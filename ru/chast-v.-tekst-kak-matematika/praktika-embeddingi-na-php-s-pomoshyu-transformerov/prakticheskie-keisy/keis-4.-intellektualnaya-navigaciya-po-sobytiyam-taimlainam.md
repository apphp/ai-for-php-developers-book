# Кейс 4. Интеллектуальная навигация по событиям / таймлайнам

#### Цель кейса

Показать, как с помощью эмбеддингов и inference можно реализовать поиск по смыслу в ленте событий или базе знаний, не прибегая к обучению моделей, сложному NLP-пайплайну или хрупким эвристикам. Кейс демонстрирует, как трансформеры в PHP превращаются из «ML‑экзотики» в обычный инженерный компонент.

#### Сценарий

Предположим, у нас есть лента событий или материалов, где каждое событие описано несколькими предложениями. Например:

– «введены новые ограничения в отношении технологических корпораций»\
– «страны региона наращивают инвестиции в спутниковые программы»\
– «обострение конфликта на политической почве в нескольких провинциях»

Пользователь вводит запрос:

«космическая гонка среди стран региона»

Очевидная проблема: ни одно из слов запроса буквально не обязано встречаться в описании событий. Классический поиск по словам здесь быстро превращается в набор костылей: синонимы, морфология, разные языки, ручные словари и бесконечные исключения.

И это не ошибка данных. Это нормальное поведение человека – формулировать мысли иначе, чем их описывает система.

#### Идея решения

Вместо попытки угадать слова мы будем искать по смыслу. Не в философском, а в сугубо инженерном смысле:

– описание события → вектор\
– запрос пользователя → вектор\
– дальше – обычный поиск ближайших значений

Эмбеддинги здесь выступают как универсальный индекс смысла. Мы переводим текст в геометрию, а дальше работаем уже с расстояниями.

Алгоритм выглядит так:

1. Берём массив событий `{id, title, description}`
2. Считаем эмбеддинг только по `description`\
   Заголовки часто слишком короткие и добавляют шум
3. Эмбеддим пользовательский запрос
4. Считаем близость запроса к каждому событию
5. Сортируем и возвращаем top‑N результатов

Без обучения моделей и без сложной инфраструктуры.

***

#### Логика работы

Вынесем всю механику в отдельный класс `SemanticEventSearch`. Этот класс не претендует на идеальную архитектуру и используется исключительно в демонстрационных целях, поэтому мы сознательно опускаем вопросы абстракций и оптимизаций.

**Плейсхолдер класса:**

```
class SemanticEventSearch
{
    // TODO: setEvents(array $events)
    // TODO: setModel(string $model)
    // TODO: setQuery(string $query)
    // TODO: __construct(int $topN = 5)
    // TODO: run(): array
}
```

Снаружи мы задаём:

– список событий через `setEvents()`\
– модель эмбеддингов через `setModel()`\
– текст запроса через `setQuery()`\
– количество результатов `topN` через конструктор

Дальше вызываем `run()` и получаем отсортированный результат.



#### Детали реализации

При первом запуске поднимается embedder:

```
pipeline('embeddings', model)
```

При этом используется каталог `.transformers-cache`. При первом обращении модель, токенизатор и веса скачиваются и сохраняются локально. Все последующие запуски используют кэш, что делает работу существенно быстрее и предсказуемее.

Для самих событий используется локальный файл `embeddings.events.json`. Это простой кэш эмбеддингов:

– при запуске мы пытаемся его прочитать\
– проверяем, совпадает ли модель в кэше с текущей\
– если для каких-то событий эмбеддингов нет, считаем их и сохраняем обратно

Таким образом эмбеддинги событий считаются один раз и переиспользуются.

***

#### Поиск

После этого логика становится тривиальной:

– эмбеддим запрос пользователя\
– нормализуем вектор (чтобы косинусная близость была стабильной)\
– считаем cosine similarity с каждым событием\
– сортируем по убыванию\
– берём top‑N

Рендер результатов (`render(query, results)`) намеренно вынесен наружу. Класс поиска возвращает только данные, а не HTML или текстовый вывод.

#### Диаграмма пайплайна семантического поиска

Чтобы зафиксировать архитектуру решения целиком, полезно посмотреть на неё не через код, а через поток данных. В этом кейсе пайплайн предельно простой и именно поэтому хорошо масштабируется.

\[IMAGE: semantic\_event\_search\_pipeline]

**Промпт для генерации картинки:** "Clean engineering pipeline diagram for semantic search. Left side: user query text. Right side: ranked events list. Middle blocks: tokenizer, transformer embedding model, vector normalization, cosine similarity. Parallel branch: events descriptions go through the same embedding model and are cached in embeddings.events.json. PHP application orchestrates the flow. Minimalistic flat style, light background, clear arrows, educational"

Диаграмма подчёркивает два ключевых момента:

Во‑первых, эмбеддинги событий считаются заранее и переиспользуются. Это превращает ML‑часть из дорогой операции в обычный кэшируемый ресурс.

Во‑вторых, запрос пользователя проходит тот же самый путь преобразования, что и данные. Благодаря этому мы сравниваем не слова, а представления в одном и том же семантическом пространстве.



#### Пример результата

```
Query: санкции против IT-компаний

[0.4288] #4 Ограничения против ИТ-сектора
  Правительство объявило о новых ограничениях для компаний, работающих в сфере информационных технологий.

[0.3356] #15 Новые правила для маркетплейсов
  Регулятор предложил требования к маркировке товаров и прозрачности комиссий на торговых онлайн-платформах.

[0.2598] #8 Утечка данных в сфере онлайн-ритейла
  Интернет-магазин расследует утечку персональных данных клиентов после компрометации учётных записей сотрудников.
```

Мы получили совпадение не по словам, а по смыслу. Самое релевантное событие оказалось первым, хотя формулировки запроса и описания различаются.

***

#### Где это применять в продакшене

Этот подход уже выглядит как продуктовый, а не экспериментальный:

– базы знаний и FAQ\
– ленты новостей и событий\
– аналитические отчёты\
– внутренние корпоративные порталы

Он слабо привязан к формулировке запроса, хорошо работает на коротких описаниях и легко комбинируется с обычными фильтрами: датой, регионом, типом события.

***

#### Ограничения и подводные камни

Важно не воспринимать семантический поиск как серебряную пулю.

Модели весят немало, и производительность нужно учитывать. Для некоторых задач обычный SQL с `LIKE` или полнотекстовый индекс будет проще и надёжнее. Но это уже нормальный инженерный разговор про trade‑off’ы, а не про магию и чёрные ящики.

Именно в таком виде трансформеры и эмбеддинги перестают быть «AI ради AI» и становятся частью поддерживаемой, объяснимой системы.

***









