# Пример 1. Траектория параметра

#### Цель

Понять, как именно параметр модели движется во время обучения.

Не итоговый коэффициент, не качество прогноза, а сам процесс: как меняется значение $$w$$ от эпохи к эпохе, как ведет себя градиент и как уменьшается ошибка.

Этот пример нужен для того, чтобы формула

$$
w = w - \eta \cdot \frac{dL}{dw}
$$

перестала быть абстрактной записью и превратилась в наблюдаемый процесс.

#### Сценарий

Мы намеренно убираем любую предметную область. Нас интересует только динамика обучения. Берем максимально простой набор данных:

```
x = [1, 2, 3, 4]
y = [2, 4, 6, 8]
```

Здесь зависимость идеальная: $$y = 2x$$.

Правильное значение параметра – $$w = 2$$.

Модель предельно простая:

$$
\hat{y} = w \cdot x
$$

Функция ошибки – среднеквадратичная (MSE). Метод оптимизации – batch gradient descent.

Начинаем обучение с $$w = 0$$.

#### Реализация на pure PHP

```php
$x = [1, 2, 3, 4];
$y = [2, 4, 6, 8]; // идеальная зависимость y = 2x

$w = 0.0;
$lr = 0.1;
$n = count($x);

echo "epoch\tw\t\tgradient\tloss\n";

for ($epoch = 1; $epoch <= 20; $epoch++) {

    $gradient = 0.0;
    $loss = 0.0;

    for ($i = 0; $i < $n; $i++) {
        $pred = $w * $x[$i];
        $error = $pred - $y[$i];

        $loss += $error ** 2;
        $gradient += $x[$i] * $error;
    }

    $loss /= $n;
    $gradient = (2 / $n) * $gradient;

    echo $epoch . "\t" .
         round($w, 4) . "\t" .
         round($gradient, 4) . "\t\t" .
         round($loss, 4) . PHP_EOL;

    $w -= $lr * $gradient;
}
```

#### Что происходит математически

Ошибка:

$$
L(w) = \frac{1}{n} \sum (w x_i - y_i)^2
$$

Производная:

$$
\frac{dL}{dw} = \frac{2}{n} \sum x_i (w x_i - y_i)
$$

Каждая эпоха делает одно и то же:

1. Считает текущую ошибку
2. Считает градиент
3. Сдвигает параметр в сторону уменьшения ошибки

#### Что важно увидеть глазами

Когда вы запускаете код, вы видите таблицу:

* эпоха
* текущее значение $$w$$
* значение градиента
* значение ошибки

И именно здесь начинается настоящее понимание.

Во-первых, пока $$w < 2$$, градиент отрицательный.&#x20;

Это означает, что формула обновления

$$
w = w - \eta \cdot gradient
$$

увеличивает $$w$$. Параметр движется вправо – к минимуму.

Во-вторых, по мере приближения к $$w = 2$$ величина градиента уменьшается. Шаги становятся короче. Движение замедляется. Это естественно: склон становится пологим.

Если learning rate выбран чуть больше оптимального, можно увидеть момент, когда параметр "перелетает" через 2. Тогда знак градиента меняется – и модель начинает корректировать движение в обратную сторону.

Именно это и есть реальная работа производной: она не говорит, где минимум. Она говорит, куда двигаться сейчас.

#### Интерпретация как движения по ландшафту

Можно представить себе график ошибки как гладкий холм.

* Пока мы на левом склоне, наклон направлен вправо
* В точке минимума наклон равен нулю
* На правом склоне наклон направлен влево

Градиент – это локальный наклон поверхности. Обновление параметра – это шаг вниз по этому наклону. Каждая строка вывода в консоли – это один шаг по поверхности ошибки.

#### Выводы

Этот пример показывает несколько фундаментальных вещей.

Во-первых, градиент – это направление движения, а не ответ. Он не сообщает нам минимум напрямую, он лишь указывает локальный склон.

Во-вторых, уменьшение шага происходит естественно. Никакой дополнительной логики не требуется – градиент сам уменьшается возле минимума.

В-третьих, обучение – это не мгновенный расчет, а последовательность маленьких коррекций.

И самое главное: формула обновления параметра перестает быть символом из учебника. Она становится реальным процессом изменения числа от эпохи к эпохе.

После этого примера градиентный спуск становится более понятным. Это просто движение по поверхности ошибки – шаг за шагом.
