# Кейс 2. Выбор модели через loss-функцию

Этот кейс логически продолжает предыдущий. Если там мы смотрели, как одна ошибка может испортить всю картину, то здесь ответим на другой практический вопрос: как формально выбрать лучшую модель, когда вариантов несколько и "на глаз" всё выглядит почти одинаково.

#### **Цель кейса**

Показать, что loss-функция превращает субъективное "кажется, эта модель лучше" в измеримый критерий, по которому можно принимать решение.

#### **Сценарий**

Представим задачу прогнозирования спроса на продукт. У нас есть исторические данные и два варианта модели:

* Модель A – простая линейная, понятная и стабильная
* Модель B – чуть более сложная, с дополнительными параметрами

Обе модели уже обучены. Мы не обсуждаем, как именно они устроены – в этом кейсе важно только одно: какая из них ошибается меньше.

Реальные значения спроса:

```php
$y = [10, 12, 15, 14, 13];
```

Предсказания модели A:

```php
$modelA = [9, 11, 14, 13, 12];
```

Предсказания модели B:

```php
$modelB = [10, 13, 15, 15, 14];
```

#### **Как мы будем сравнивать модели**

Мы используем ту же функцию MSE, что и в предыдущем кейсе:

```php
function mse(array $y, array $yHat): float {
    $n = count($y);
    $sum = 0.0;

    for ($i = 0; $i < $n; $i++) {
        $diff = $y[$i] - $yHat[$i];
        $sum += $diff * $diff;
    }

    return $sum / max($n, 1);
}

echo "MSE A: " . mse($y, $modelA) . PHP_EOL;
echo "MSE B: " . mse($y, $modelB) . PHP_EOL;

// Результат:
// MSE A: 1
// MSE B: 0.6
```

Важно подчеркнуть: мы не сравниваем сами предсказания напрямую, мы сравниваем ошибки, агрегированные через выбранную loss-функцию.

#### **Что происходит на интуитивном уровне**

Если посмотреть на массивы чисел, кажется, что обе модели ведут себя похоже. Они почти везде промахиваются на одну и ту же величину. Где-то одна чуть лучше, где-то другая.

Именно в таких ситуациях человек начинает рассуждать:

* "разница несущественная"
* и так сойдёт
* обе модели нормальные

Loss-функция убирает эту неопределённость.

#### **Результат сравнения**

После вычисления MSE мы получаем два конкретных числа. Одно из них меньше – и это единственный формальный аргумент, который действительно важен для обучения и выбора модели.

Даже если разница между MSE невелика, она всё равно отражает систематическое преимущество одной модели над другой в рамках выбранной философии ошибки.

#### **Почему это принципиально важно**

Модель машинного обучения не "видит" графики, таблицы и красивые визуализации. Она живёт в мире чисел. Для неё:

* нет "почти одинаково"
* нет "визуально лучше"
* есть только меньшее или большее значение loss

Поэтому именно loss-функция становится:

* критерием выбора модели
* основой для автоматического подбора параметров
* метрикой остановки обучения

#### **Ограничение этого подхода**

Важно помнить, что мы сравниваем модели через призму MSE. А значит:&#x20;

* большие ошибки важнее маленьких
* выбросы имеют повышенный вес
* мы оцениваем средний квадрат отклонения

Если бы мы выбрали другую loss-функцию, вывод мог бы измениться.

#### **Выводы**

В этом кейсе важно не то, что одна модель оказалась лучше другой. Важно другое:

* loss-функция превращает выбор модели в формальную процедуру
* даже небольшая разница в ошибке имеет значение
* модель оптимизируется не под "красивые предсказания", а под минимизацию loss.

Даже если визуально разница кажется небольшой, loss даёт численное основание для выбора.

Это подводит нас к следующему шагу: если loss определяет, какая модель лучше, то обучение модели – это систематическое уменьшение этого числа. Именно к этому мы и перейдём дальше.

{% hint style="info" %}
Чтобы самостоятельно протестировать этот код, установите примеры из официального репозитория [GitHub](https://github.com/apphp/ai-for-php-developers-examples) или воспользуйтесь [онлайн-демонстрацией](https://aiwithphp.org/books/ai-for-php-developers/examples/part-2/errors-and-loss-functions) для его запуска.
{% endhint %}
