# Кейс 2. Выбор модели через loss-функцию

Этот кейс логически продолжает предыдущий. Если там мы смотрели, как одна ошибка может испортить всю картину, то здесь ответим на другой практический вопрос: как формально выбрать лучшую модель, когда вариантов несколько и "на глаз" всё выглядит почти одинаково.

#### **Цель кейса**

Показать, что loss-функция превращает субъективное "кажется, эта модель лучше" в измеримый критерий, по которому можно принимать решение.

#### **Сценарий**

Представим задачу прогнозирования спроса на продукт. У нас есть исторические данные и два варианта модели:

* Модель A – простая линейная, понятная и стабильная
* Модель B – чуть более сложная, с дополнительными параметрами

Обе модели уже обучены. Мы не обсуждаем, как именно они устроены – в этом кейсе важно только одно: какая из них ошибается меньше.

Реальные значения спроса:

```php
$y = [10, 12, 15, 14, 13];
```

Предсказания модели A:

```php
$modelA = [9, 11, 14, 13, 12];
```

Предсказания модели B:

```php
$modelB = [10, 13, 15, 15, 14];
```

#### **Как мы будем сравнивать модели**

Мы используем ту же функцию MSE, что и в предыдущем кейсе:

```php
function mse(array $y, array $yHat): float {
    $n = max(count($y), 1);
    $sum = 0.0;

    for ($i = 0; $i < $n; $i++) {
        $diff = $y[$i] - $yHat[$i];
        $sum += $diff * $diff;
    }

    return $sum / $n;
}

echo "MSE A: " . mse($y, $modelA) . PHP_EOL;
echo "MSE B: " . mse($y, $modelB) . PHP_EOL;
```

Важно подчеркнуть: мы не сравниваем сами предсказания напрямую, мы сравниваем ошибки, агрегированные через выбранную loss-функцию.

#### **Что происходит на интуитивном уровне**

Если посмотреть на массивы чисел, кажется, что обе модели ведут себя похоже. Они почти везде промахиваются на одну и ту же величину. Где-то одна чуть лучше, где-то другая.

<br>

Именно в таких ситуациях человек начинает рассуждать:

<br>

– «разница несущественная»

– «и так сойдёт»

– «обе модели нормальные»

<br>

Loss-функция убирает эту неопределённость.

***

**Результат сравнения**

После вычисления MSE мы получаем два конкретных числа. Одно из них меньше – и это единственный формальный аргумент, который действительно важен для обучения и выбора модели.

<br>

Даже если разница между MSE невелика, она всё равно отражает систематическое преимущество одной модели над другой в рамках выбранной философии ошибки.

***

**Почему это принципиально важно**

Модель машинного обучения не «видит» графики, таблицы и красивые визуализации. Она живёт в мире чисел. Для неё:

<br>

– нет «почти одинаково»

– нет «визуально лучше»

– есть только меньше или больше loss

<br>

Поэтому именно loss-функция становится:

– критерием выбора модели

– основой для автоматического подбора параметров

– метрикой остановки обучения

***

**Ограничение этого подхода**

Важно помнить, что мы сравниваем модели через призму MSE. А значит:

<br>

– большие ошибки важнее маленьких

– выбросы имеют повышенный вес

– мы оцениваем средний квадрат отклонения

<br>

Если бы мы выбрали другую loss-функцию, вывод мог бы измениться.

***

**Выводы**

В этом кейсе важно не то, что одна модель оказалась лучше другой. Важно другое:

<br>

– loss-функция превращает выбор модели в формальную процедуру

– даже небольшая разница в ошибке имеет значение

– модель оптимизируется не под «красивые предсказания», а под минимизацию loss

<br>

Это подводит нас к следующему шагу: если loss определяет, какая модель лучше, то обучение модели – это систематическое уменьшение этого числа. Именно к этому мы и перейдём дальше.







###

Сценарий

Есть две модели прогнозирования спроса:

– простая линейная

– чуть более сложная

Мы хотим формально выбрать лучшую.

Цель кейса

Показать, что loss-функция – это объективный критерий выбора модели.



```
$y = [10, 12, 15, 14, 13];

$modelA = [9, 11, 14, 13, 12];
$modelB = [10, 13, 15, 15, 14];

echo "MSE A: " . mse($y, $modelA) . PHP_EOL;
echo "MSE B: " . mse($y, $modelB) . PHP_EOL;
```

Идея для пояснения

Даже если визуально разница кажется небольшой, loss даёт численное основание для выбора.

