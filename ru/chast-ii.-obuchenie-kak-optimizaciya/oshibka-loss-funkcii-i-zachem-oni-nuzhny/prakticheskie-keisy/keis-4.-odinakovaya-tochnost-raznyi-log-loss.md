# Кейс 4. Одинаковая точность – разный log loss

На практике часто ограничиваются метрикой [accuracy](../../../vvedenie/glossarii.md#accuracy-tochnost-klassifikacii) – долей объектов, для которых модель дала правильный ответ. Это удобно, интуитивно и... опасно. В этом кейсе мы покажем ситуацию, где две модели имеют одинаковую точность, но при этом одна из них объективно лучше в терминах вероятностных предсказаний, и это видно только через [loss-функцию](../../../vvedenie/glossarii.md#loss-funkciya-funkciya-poter).

#### Цель кейса

Понять, почему:

* accuracy не отражает качество вероятностных предсказаний
* loss-функция (в частности log loss) несёт больше информации
* "уверенность модели" должна быть частью оценки качества

#### Сценарий

Представим бинарную классификацию. Есть четыре наблюдения с истинными метками:

```php
$y = [1, 0, 1, 0];
```

Две модели выдают вероятности принадлежности к классу 1 $$(p(y = 1 | x))$$.

Модель A – уверенная:

```php
$modelA = [0.9, 0.2, 0.9, 0.2];
```

Модель B – осторожная:

```php
$modelB = [0.6, 0.4, 0.6, 0.4];
```

Если мы применим стандартный порог 0.5 (что типично для бинарной классификации), обе модели дадут одинаковые классы:

<table data-header-hidden><thead><tr><th width="119.2265625"></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>y</td><td>Model A</td><td>Model B</td><td>Предсказанный класс</td></tr><tr><td>1</td><td>0.9</td><td>0.6</td><td>1</td></tr><tr><td>0</td><td>0.2</td><td>0.4</td><td>0</td></tr><tr><td>1</td><td>0.9</td><td>0.6</td><td>1</td></tr><tr><td>0</td><td>0.2</td><td>0.4</td><td>0</td></tr></tbody></table>

Accuracy у обеих моделей равна 100%.

#### Реализация log loss

Используем стандартную бинарную [log loss](../../../vvedenie/glossarii.md#log-loss-logarifmicheskaya-funkciya-poter). Математически log loss определяется следующей формулой:

$$
L = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log(p_i) + (1 - y_i)\log(1 - p_i) \right]
$$

```php
function logLoss(array $y, array $p, float $eps = 1e-15): float {
    $loss = 0.0;
    $n = count($y);

    for ($i = 0; $i < $n; $i++) {
        $pi = max($eps, min(1 - $eps, $p[$i]));
        $loss += $y[$i] * log($pi) + (1 - $y[$i]) * log(1 - $pi);
    }

    return -$loss / $n;
}

echo "Log loss A: " . logLoss($y, $modelA) . PHP_EOL;
echo "Log loss B: " . logLoss($y, $modelB) . PHP_EOL;
```

Результат будет примерно таким:

```
Log loss A: 0.164
Log loss B: 0.511
```

#### Что здесь произошло на самом деле

Обе модели:

* сделали одинаковые классификационные решения
* получили одинаковый accuracy
* выглядят "равноценными", если смотреть только на классы

Но с точки зрения оценки вероятностей:

* Model A делает уверенные предсказания: "Я почти уверена".
* Model B даёт более осторожные оценки: "Я скорее думаю так, но не ручаюсь".

Log loss учитывает это различие.

#### Почему log loss считает Model A лучше

Log loss – это не просто мера ошибки, а штраф за несоответствие уверенности реальности.

Он:

* поощряет высокую уверенность, если модель права
* резко наказывает высокую уверенность, если модель ошиблась
* делает честность вероятностей частью оптимизации

Важно, что высокая уверенность сама по себе не является ни хорошей, ни плохой. Она становится проблемой только тогда, когда модель уверена и ошибается.

Таким образом, в этом кейсе&#x20;

* Model A: уверена и права, но получает меньший loss
* Model B: менее уверена, хотя тоже права, и поэтому получает более высокий loss за менее информативные вероятности

#### Ключевой вывод

Accuracy отвечает на вопрос:

> "Сколько раз модель угадала класс?"

Log loss отвечает на принципиально другой вопрос:

> "Насколько можно доверять вероятностям, которые она выдаёт?"

Две модели могут быть одинаково точными, но не одинаково полезными.

#### Практический смысл

Этот кейс объясняет, почему:

* в задачах скоринга, рекомендаций и риск-моделей accuracy почти бесполезен
* loss-функция – это часть постановки задачи, а не техническая деталь
* вероятности – это не побочный продукт модели, а основной результат

Когда модель слишком уверена и при этом ошибается, это плохо. В реальных задачах важно оценивать не только правильность ответов, но и то, насколько можно доверять её вероятностям.
