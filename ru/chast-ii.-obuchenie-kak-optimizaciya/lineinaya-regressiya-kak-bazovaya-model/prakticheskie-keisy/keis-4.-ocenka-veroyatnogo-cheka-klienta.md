# Кейс 4. Оценка вероятного чека клиента

#### Суть кейса

Этот кейс относится к классическим задачам e-commerce и SaaS, но при этом почти всегда недооценивается. Речь идёт не о бинарном вопросе "купит или нет", а о более практичном и полезном для бизнеса прогнозе – какой чек можно ожидать от конкретного визита пользователя.

Такая модель может использоваться в самых разных местах: для персональных скидок, динамического ранжирования товаров, оценки эффективности рекламного трафика или даже для решения, стоит ли вообще тратить ресурсы на удержание конкретного пользователя.

#### Признаки

Мы используем только поведенческие признаки, которые легко собрать без сбора персональных данных:

* $$x_1$$ - количество посещений сайта за период
* $$x_2$$ - общее время на сайте
* $$x_3$$ - количество просмотренных товаров
* $$x_4$$ - применённая скидка (в процентах)

Все признаки числовые и интуитивно понятные бизнесу – это важно, потому что модель должна не только работать, но и объясняться.

#### Цель

Предсказать ожидаемую сумму заказа (чек) в денежных единицах.

Важно подчеркнуть: мы не пытаемся угадать точную сумму до цента. Нас интересует ожидаемый уровень чека, пригодный для принятия решений – например, показать ли пользователю дополнительный upsell или ограничиться базовым предложением.

#### Почему здесь линейная регрессия

Линейная регрессия в этом кейсе выступает как осознанный baseline, а не как упрощение "потому что проще".

Во-первых, она быстро обучается и дешёва в инференсе – это критично для real-time систем.

Во-вторых, веса модели легко интерпретировать: можно буквально сказать маркетингу, что "каждый дополнительный просмотр товара в среднем изменяет чек на определённый процент".

В-третьих, линейная модель позволяет очень рано обнаружить проблемы в данных: шум, перекосы, неадекватные признаки.

И только когда этот baseline становится понятен и прозрачен, имеет смысл переходить к более сложным моделям.

#### Особенность данных: асимметрия чека

В реальных e-commerce данных распределение чека почти никогда не бывает нормальным. Обычно это длинный хвост: много маленьких заказов и редкие, но очень большие.

Из-за этого прямая регрессия по чеку часто даёт нестабильные веса и переобучается на выбросы. Простой и эффективный приём – логарифмирование целевой переменной.

Мы обучаем модель предсказывать `log` (чек), а уже на этапе использования возвращаемся к исходной шкале через `exp`. Это делает обучение заметно устойчивее и снижает влияние аномально больших заказов. При этом важно понимать, что после обратного преобразования модель фактически предсказывает типичный (медианный) чек, а не строгое математическое ожидание, что в большинстве продуктовых сценариев является допустимым приближением.

#### Нормализация признаков

В этом кейсе признаки находятся в разных шкалах: количество посещений – десятки, время на сайте – тысячи секунд, скидка – проценты.

Для линейной модели это означает, что веса будут несопоставимы и обучение станет чувствительным к масштабу. Поэтому здесь особенно полезно показать нормализацию признаков – не как магию, а как инженерную необходимость. Даже простая стандартизация (mean = 0, std = 1) делает модель стабильнее и ускоряет сходимость.

В примере ниже для наглядности используется необработанный датасет, но в реальном пайплайне нормализация применяется перед обучением модели.

#### Реализация на PHP с Rubix ML

Для реализации используем Rubix ML и линейную регрессию с [L2-регуляризацией](../../../vvedenie/zaklyuchitelnye-materialy/glossarii.md#l2-regulyarizaciya) (Ridge). Регуляризация здесь важна: поведенческие признаки часто коррелируют между собой, и Ridge помогает избежать раздутых весов.

```php
use Rubix\ML\Datasets\Labeled;
use Rubix\ML\Regressors\Ridge;

// Признаки: визиты, время на сайте, просмотры, скидка
$samples = [
    [3, 420, 5, 0],
    [10, 1800, 20, 10],
    [1, 120, 2, 0],
    [7, 900, 12, 5],
];

// Логарифм чека
$labels = [
    log(3500),
    log(12000),
    log(1800),
    log(7200),
];

$dataset = Labeled::build($samples, $labels);

$model = new Ridge(1.0);
$model->train($dataset);
```

**Предсказание чека**

```php
// Предсказание
$customer = [5, 600, 8, 5];

$unlabeled = new Unlabeled([$customer]);
$logPrice = $model->predict($unlabeled);
$predictedPrice = exp($logPrice[0]);

echo 'Прогнозируемый чек: ' . round($predictedPrice, 2) . PHP_EOL;
echo 'Прогнозируемый log(чек): ' . round($logPrice[0], 6) . PHP_EOL . PHP_EOL;

// Результат: 
// Прогнозируемый чек: 3661.71
// Прогнозируемый log(чек): 8.205686
```

Даже в таком минимальном примере можно увидеть ключевые идеи: регуляризация, работа с масштабами и осознанный выбор целевой переменной.

#### Интерпретация весов

Посмотри на получившиеся веса признаков:

```php
$weights = $model->coefficients();
$bias = $model->bias()

echo 'Коэффициенты (веса признаков):' . PHP_EOL;
echo '0-посещения, 1-время на сайте, 2-просмотры страниц, 3-процент скидки' . PHP_EOL;
print_r($weights);

echo PHP_EOL . 'Bias (intercept): ' . $bias . PHP_EOL;

// Результат:   
// Коэффициенты (веса признаков):  
// Array (
//    [0] => 0.14071907246965
//    [1] => -0.00012872304457004
//    [2] => 0.092300948419521
//    [3] => -0.085823519417687
// )
// Bias (intercept): 7.2700340926455
```

После обучения модель даёт веса, которые можно интерпретировать на человеческом языке:

* положительный вес у количества просмотров – ожидаем
* слабый или положительный вес у времени на сайте – логично
* отрицательный или слабоположительный вес у скидки – частый и важный сигнал (скидки не всегда увеличивают чек)

Это тот редкий случай, когда ML-модель не спорит с интуицией бизнеса, а уточняет её.

Как и в предыдущих кейсах, линейная модель ценна своей интерпретируемостью.

#### Ограничения модели

Этот кейс также честно показывает границы линейной регрессии:

* ей сложно учитывать нелинейные эффекты (например, когда рост времени на сайте перестаёт давать эффект)
* не учитывает порядок действий пользователя
* чувствительна к шуму и плохой аналитике событий

Но именно поэтому она идеальна как первая модель, с которой начинается взросление ML в продукте.

#### Выводы

Этот кейс показывает, что машинное обучение в e-commerce – это не обязательно нейросети и сложные пайплайны. Иногда достаточно простой линейной модели, чтобы:

* получить измеримый бизнес-эффект
* объяснить результат не-техническим командам
* заложить основу для дальнейшего усложнения

Линейная регрессия здесь – не компромисс, а инструмент мышления. Именно с таких кейсов и начинается осознанный ML в продакшене.

{% hint style="info" %}
Чтобы самостоятельно протестировать этот код, установите примеры из официального репозитория [GitHub](https://github.com/apphp/ai-for-php-developers-examples) или воспользуйтесь [онлайн-демонстрацией](https://aiwithphp.org/books/ai-for-php-developers/examples/part-2/linear-regression-as-basic-model) для его запуска.
{% endhint %}
