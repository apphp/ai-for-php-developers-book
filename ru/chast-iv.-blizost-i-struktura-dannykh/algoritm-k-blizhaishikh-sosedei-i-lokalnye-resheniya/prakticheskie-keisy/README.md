# Практические кейсы

Алгоритм k-ближайших соседей часто воспринимают как учебный или "игрушечный". Он прост, не обучает явную модель и плохо масштабируется на большие данные. Но именно эта простота делает k-NN идеальным инструментом для практического понимания машинного обучения.

В предыдущей главе мы разобрали геометрическую интуицию k-NN, роль метрик расстояния и идею локальных решений. Теперь пришло время посмотреть, как всё это выглядит в коде – без абстракций и скрытой магии.

Практические кейсы в этой главе построены по нарастающей:

* сначала ручная реализация на чистом PHP, где каждое вычисление расстояния и каждое решение можно проследить пошагово
* затем пример регрессии, показывающий, что k-NN – это не только классификация, но и локальное усреднение
* и, наконец, та же логика, реализованная через RubixML, чтобы связать интуитивное понимание с реальной библиотекой.

Важно, что цель этих кейсов – не оптимизация и не промышленный продакшен. Их цель – сформировать правильное мышление: машинное обучение – это не набор "умных" моделей, а прежде всего работа с расстояниями, соседствами и локальной структурой данных.

Если вы понимаете, как работает k-NN в этих примерах, вам будет гораздо легче понять более сложные алгоритмы, которые делают то же самое, но менее очевидным образом.
